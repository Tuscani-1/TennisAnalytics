{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Machine Learning Model Building\n",
    "\n",
    "In this notebook, we'll use the dataset elaborated in the previous step to build several machine learning models, including logistic regression, support vector machine, decision tree, k-nearest neighbor and finally a deep learning model.\n",
    "\n",
    "All of these models will try to classify each match into '0' or '1' depending on who's more likely to win each match based on the match features, player 0 or player 1.\n",
    "\n",
    "Finally, we'll compare these models to see which one is more appropriate in our context, and we'll save only one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import pandas library since we're going to work with csv files and dataframe objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the csv file saved in the last notebook, where we added extra-features to help our model make a better prediction job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"csv/FeatureCalculated_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Player 0</th>\n",
       "      <th>Player 1</th>\n",
       "      <th>Pl0_Rank</th>\n",
       "      <th>Pl1_Rank</th>\n",
       "      <th>Max_Pl0</th>\n",
       "      <th>Max_Pl1</th>\n",
       "      <th>Avg_Pl0</th>\n",
       "      <th>Avg_Pl1</th>\n",
       "      <th>Won</th>\n",
       "      <th>...</th>\n",
       "      <th>The Final</th>\n",
       "      <th>Rank Index</th>\n",
       "      <th>Pl0 Recent Form</th>\n",
       "      <th>Pl0 Form</th>\n",
       "      <th>Pl1 Recent Form</th>\n",
       "      <th>Pl1 Form</th>\n",
       "      <th>Pl0 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl1 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl0 Surface Performance</th>\n",
       "      <th>Pl1 Surface Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>Ljubicic I.</td>\n",
       "      <td>Dosedel S.</td>\n",
       "      <td>77</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0182</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>Enqvist T.</td>\n",
       "      <td>Clement A.</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7614</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>Baccanello P.</td>\n",
       "      <td>Escude N.</td>\n",
       "      <td>655</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.8309</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>Federer R.</td>\n",
       "      <td>Knippschild J.</td>\n",
       "      <td>65</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>Woodbridge T.</td>\n",
       "      <td>Fromberg R.</td>\n",
       "      <td>198</td>\n",
       "      <td>81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.2478</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 146 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Player 0        Player 1  Pl0_Rank  Pl1_Rank  Max_Pl0  \\\n",
       "0  2000-03-01    Ljubicic I.      Dosedel S.        77        63      NaN   \n",
       "1  2000-03-01     Enqvist T.      Clement A.         5        56      NaN   \n",
       "2  2000-03-01  Baccanello P.       Escude N.       655        40      NaN   \n",
       "3  2000-03-01     Federer R.  Knippschild J.        65        87      NaN   \n",
       "4  2000-03-01  Woodbridge T.     Fromberg R.       198        81      NaN   \n",
       "\n",
       "   Max_Pl1  Avg_Pl0  Avg_Pl1  Won  ...  The Final  Rank Index  \\\n",
       "0      NaN      NaN      NaN  1.0  ...          0     -0.0182   \n",
       "1      NaN      NaN      NaN  0.0  ...          0      0.7614   \n",
       "2      NaN      NaN      NaN  1.0  ...          0     -0.8309   \n",
       "3      NaN      NaN      NaN  0.0  ...          0      0.0366   \n",
       "4      NaN      NaN      NaN  1.0  ...          0     -0.2478   \n",
       "\n",
       "   Pl0 Recent Form  Pl0 Form  Pl1 Recent Form  Pl1 Form  \\\n",
       "0             0.43      0.43             0.67      0.67   \n",
       "1             0.57      0.60             0.50      0.50   \n",
       "2             0.00      0.00             0.67      0.67   \n",
       "3             0.71      0.70             0.00      0.00   \n",
       "4             0.50      0.50             0.71      0.62   \n",
       "\n",
       "   Pl0 Perf. vs Similar Opponent  Pl1 Perf. vs Similar Opponent  \\\n",
       "0                           0.66                           0.17   \n",
       "1                           0.58                           0.24   \n",
       "2                           0.00                           0.91   \n",
       "3                           0.90                           0.30   \n",
       "4                           0.29                           0.36   \n",
       "\n",
       "   Pl0 Surface Performance  Pl1 Surface Performance  \n",
       "0                     0.62                     0.40  \n",
       "1                     0.56                     0.51  \n",
       "2                     0.14                     0.64  \n",
       "3                     0.83                     0.10  \n",
       "4                     0.27                     0.46  \n",
       "\n",
       "[5 rows x 146 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before picking up our models, we have to extract the inputs and the targets from this dataset.\n",
    "The target variable is only one, the \"Won\" column.\n",
    "The inputs variables start with the dummy categories we introduced in the preprocessing stage until the last columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date',\n",
       " 'Player 0',\n",
       " 'Player 1',\n",
       " 'Pl0_Rank',\n",
       " 'Pl1_Rank',\n",
       " 'Max_Pl0',\n",
       " 'Max_Pl1',\n",
       " 'Avg_Pl0',\n",
       " 'Avg_Pl1',\n",
       " 'Won',\n",
       " 'Acapulco',\n",
       " 'Adelaide',\n",
       " 'Amersfoort',\n",
       " 'Amsterdam',\n",
       " 'Atlanta',\n",
       " 'Auckland',\n",
       " 'Bangkok',\n",
       " 'Barcelona',\n",
       " 'Basel',\n",
       " 'Bastad',\n",
       " 'Beijing',\n",
       " 'Belgrade',\n",
       " 'Bogota',\n",
       " 'Brighton',\n",
       " 'Brisbane',\n",
       " 'Bucharest',\n",
       " 'Buenos Aires',\n",
       " 'Casablanca',\n",
       " 'Chennai',\n",
       " 'Cincinnati',\n",
       " 'Copenhagen',\n",
       " 'Costa Do Sauipe',\n",
       " 'Delray Beach',\n",
       " 'Doha',\n",
       " 'Dubai',\n",
       " 'Dusseldorf',\n",
       " 'Eastbourne',\n",
       " 'Estoril',\n",
       " 'Geneva',\n",
       " 'Gstaad',\n",
       " 'Halle',\n",
       " 'Hamburg',\n",
       " 'Ho Chi Min City',\n",
       " 'Hong Kong',\n",
       " 'Houston',\n",
       " 'Indian Wells',\n",
       " 'Indianapolis',\n",
       " 'Istanbul',\n",
       " 'Johannesburg',\n",
       " 'Kitzbuhel',\n",
       " 'Kuala Lumpur',\n",
       " 'Las Vegas',\n",
       " 'Lisbon',\n",
       " 'London',\n",
       " 'Long Island',\n",
       " 'Los Angeles',\n",
       " 'Los Cabos',\n",
       " 'Lyon',\n",
       " 'Madrid',\n",
       " 'Mallorca',\n",
       " 'Marrakech',\n",
       " 'Marseille',\n",
       " 'Melbourne',\n",
       " 'Memphis',\n",
       " 'Metz',\n",
       " 'Mexico City',\n",
       " 'Miami',\n",
       " 'Milan',\n",
       " 'Monte Carlo',\n",
       " 'Montpellier',\n",
       " 'Montreal',\n",
       " 'Moscow',\n",
       " 'Mumbai',\n",
       " 'Munich',\n",
       " 'New Haven',\n",
       " 'New York',\n",
       " 'Newport',\n",
       " 'Nice',\n",
       " 'Nottingham',\n",
       " 'Oeiras',\n",
       " 'Orlando',\n",
       " 'Palermo',\n",
       " 'Paris',\n",
       " 'Portschach',\n",
       " 'Queens Club',\n",
       " 'Quito',\n",
       " 'Rio de Janeiro',\n",
       " 'Rome',\n",
       " 'Rotterdam',\n",
       " 'Salvador',\n",
       " 'San Jose',\n",
       " 'San Marino',\n",
       " 'Santiago',\n",
       " 'Sao Paulo',\n",
       " 'Scottsdale',\n",
       " 'Shanghai',\n",
       " 'Shenzhen',\n",
       " 'Sofia',\n",
       " 'Sopot',\n",
       " 'St. Petersburg',\n",
       " 'St. Polten',\n",
       " 'Stockholm',\n",
       " 'Stuttgart',\n",
       " 'Sydney',\n",
       " 'Tashkent',\n",
       " 'Tokyo',\n",
       " 'Toronto',\n",
       " 'Toulouse',\n",
       " 'Umag',\n",
       " 'Valencia',\n",
       " 'Vienna',\n",
       " 'Vina del Mar',\n",
       " 'Warsaw',\n",
       " 'Washington',\n",
       " 'Winston-Salem',\n",
       " 'Zagreb',\n",
       " 's-Hertogenbosch',\n",
       " 'Indoor',\n",
       " 'Outdoor',\n",
       " 'Carpet',\n",
       " 'Clay',\n",
       " 'Grass',\n",
       " 'Hard',\n",
       " 'ATP250',\n",
       " 'ATP500',\n",
       " 'Grand Slam',\n",
       " 'Masters 1000',\n",
       " 'Masters Cup',\n",
       " '0th Round',\n",
       " '1st Round',\n",
       " '2nd Round',\n",
       " '3rd Round',\n",
       " '4th Round',\n",
       " 'Quarterfinals',\n",
       " 'Round Robin',\n",
       " 'Semifinals',\n",
       " 'The Final',\n",
       " 'Rank Index',\n",
       " 'Pl0 Recent Form',\n",
       " 'Pl0 Form',\n",
       " 'Pl1 Recent Form',\n",
       " 'Pl1 Form',\n",
       " 'Pl0 Perf. vs Similar Opponent',\n",
       " 'Pl1 Perf. vs Similar Opponent',\n",
       " 'Pl0 Surface Performance',\n",
       " 'Pl1 Surface Performance']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = df.iloc[:, 10:]\n",
    "targets = df.iloc[:, 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at \"inputs\" and \"targets\" content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acapulco</th>\n",
       "      <th>Adelaide</th>\n",
       "      <th>Amersfoort</th>\n",
       "      <th>Amsterdam</th>\n",
       "      <th>Atlanta</th>\n",
       "      <th>Auckland</th>\n",
       "      <th>Bangkok</th>\n",
       "      <th>Barcelona</th>\n",
       "      <th>Basel</th>\n",
       "      <th>Bastad</th>\n",
       "      <th>...</th>\n",
       "      <th>The Final</th>\n",
       "      <th>Rank Index</th>\n",
       "      <th>Pl0 Recent Form</th>\n",
       "      <th>Pl0 Form</th>\n",
       "      <th>Pl1 Recent Form</th>\n",
       "      <th>Pl1 Form</th>\n",
       "      <th>Pl0 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl1 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl0 Surface Performance</th>\n",
       "      <th>Pl1 Surface Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0182</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7614</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.8309</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.2478</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Acapulco  Adelaide  Amersfoort  Amsterdam  Atlanta  Auckland  Bangkok  \\\n",
       "0         0         1           0          0        0         0        0   \n",
       "1         0         1           0          0        0         0        0   \n",
       "2         0         1           0          0        0         0        0   \n",
       "3         0         1           0          0        0         0        0   \n",
       "4         0         1           0          0        0         0        0   \n",
       "\n",
       "   Barcelona  Basel  Bastad  ...  The Final  Rank Index  Pl0 Recent Form  \\\n",
       "0          0      0       0  ...          0     -0.0182             0.43   \n",
       "1          0      0       0  ...          0      0.7614             0.57   \n",
       "2          0      0       0  ...          0     -0.8309             0.00   \n",
       "3          0      0       0  ...          0      0.0366             0.71   \n",
       "4          0      0       0  ...          0     -0.2478             0.50   \n",
       "\n",
       "   Pl0 Form  Pl1 Recent Form  Pl1 Form  Pl0 Perf. vs Similar Opponent  \\\n",
       "0      0.43             0.67      0.67                           0.66   \n",
       "1      0.60             0.50      0.50                           0.58   \n",
       "2      0.00             0.67      0.67                           0.00   \n",
       "3      0.70             0.00      0.00                           0.90   \n",
       "4      0.50             0.71      0.62                           0.29   \n",
       "\n",
       "   Pl1 Perf. vs Similar Opponent  Pl0 Surface Performance  \\\n",
       "0                           0.17                     0.62   \n",
       "1                           0.24                     0.56   \n",
       "2                           0.91                     0.14   \n",
       "3                           0.30                     0.83   \n",
       "4                           0.36                     0.27   \n",
       "\n",
       "   Pl1 Surface Performance  \n",
       "0                     0.40  \n",
       "1                     0.51  \n",
       "2                     0.64  \n",
       "3                     0.10  \n",
       "4                     0.46  \n",
       "\n",
       "[5 rows x 136 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    0.0\n",
       "2    1.0\n",
       "3    0.0\n",
       "4    1.0\n",
       "Name: Won, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to split the data into training and testing data.\n",
    "We'll use a 75:25 split, and since we assume each match is independent from the others, we won't shuffle the data randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(inputs, targets, test_size=0.25, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Let's start off with the logistic regression, and see how accurately predicts winners and losers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lreg = LogisticRegression(max_iter=10000, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=2,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lreg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7269141730258081\n"
     ]
    }
   ],
   "source": [
    "score = lreg.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression predicts correctly almost 3 matches out of 4!\n",
    "\n",
    "Since we structured our data to have as many '0' targets than '1' targets, a random model would have approximately 50% accuracy.\n",
    "Jumping from 50% to almost 73% is definetely a good result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "Another popular classifier model is the SVM, Support Vector Machine.\n",
    "Let's see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(kernel = 'rbf')\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7247706422018348\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM model has a 0.724 accuracy, very similar to the Logistic Regression model!\n",
    "Let's see if we can find better models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier\n",
    "\n",
    "Let's try out the Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6500900282946068\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Decision Tree model, as we can see, is not a very good choice. It returns only a 0.65 prediction accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors\n",
    "\n",
    "Let's see if the KNN model can do a better job than the Logistic Regression and the SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the KNN model we have to pick the right K value, so we're going to fit our model with several values from 1 to 8, and we'll compare the errors of each run.\n",
    "Finally, we'll run the model with the appropriate K value and check its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = []\n",
    "\n",
    "# Calculating error for K values between 1 and 8\n",
    "for i in range(1, 9):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(x_train, y_train)\n",
    "    pred_i = knn.predict(x_test)\n",
    "    error.append(np.mean(pred_i != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Mean Error')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, 9), error, color='red', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='blue', markersize=10)\n",
    "plt.title('Error Rate K Value')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('Mean Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the plot above, we obtain the lowest error with K = 8, so let's use 8 as K parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=8, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=8)\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.76      0.70      5832\n",
      "         1.0       0.71      0.59      0.65      5831\n",
      "\n",
      "    accuracy                           0.68     11663\n",
      "   macro avg       0.68      0.68      0.67     11663\n",
      "weighted avg       0.68      0.68      0.67     11663\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN accuracy is around 0.67 / 0.68, so not that great.\n",
    "Let's try Neural Networks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Networks\n",
    "\n",
    "Finally, let's see if we can build a neural network that can achieve a greater accuracy than the Logistic Regression and SVM models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = inputs.shape[1]\n",
    "\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(1000, input_dim=input_cols, activation='relu'))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(60, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dense(7, activation='relu'))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "34989/34989 [==============================] - 7s 193us/step - loss: 0.6290 - accuracy: 0.6778\n",
      "Epoch 2/10\n",
      "34989/34989 [==============================] - 7s 190us/step - loss: 0.5988 - accuracy: 0.6998\n",
      "Epoch 3/10\n",
      "34989/34989 [==============================] - 7s 198us/step - loss: 0.5869 - accuracy: 0.7027\n",
      "Epoch 4/10\n",
      "34989/34989 [==============================] - 7s 192us/step - loss: 0.5762 - accuracy: 0.7064\n",
      "Epoch 5/10\n",
      "34989/34989 [==============================] - 7s 190us/step - loss: 0.5705 - accuracy: 0.7071\n",
      "Epoch 6/10\n",
      "34989/34989 [==============================] - 7s 194us/step - loss: 0.5634 - accuracy: 0.7099\n",
      "Epoch 7/10\n",
      "34989/34989 [==============================] - 7s 206us/step - loss: 0.5582 - accuracy: 0.7117\n",
      "Epoch 8/10\n",
      "34989/34989 [==============================] - 8s 227us/step - loss: 0.5550 - accuracy: 0.7121\n",
      "Epoch 9/10\n",
      "34989/34989 [==============================] - 8s 216us/step - loss: 0.5495 - accuracy: 0.7147\n",
      "Epoch 10/10\n",
      "34989/34989 [==============================] - 7s 187us/step - loss: 0.5473 - accuracy: 0.7136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1c01343ea08>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11663/11663 [==============================] - 1s 90us/step\n",
      "Test accuracy: 0.7239132523536682\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we achieved around 0.724 accuracy, almost enough to beat the Logistic Regression model.\n",
    "\n",
    "However, we'll decide to make use of the Logistic Regression model since we can predicts probabilities that each player has to win the match!\n",
    "\n",
    "In this way, we can define the \"predicted\" odds for any given match calculating the logistic regression formula on the inputs features.\n",
    "\n",
    "So let's save our Logistic Regression model, we're going to use it in the next notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'logistic_regression.lr'\n",
    "pickle.dump(lreg, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have saved our model, let's create a coefficients dataframe, so that we associate each input column with the appropriate weight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(inputs.columns)\n",
    "coefs = lreg.coef_.tolist()[0]\n",
    "\n",
    "coef_df_list = []\n",
    "for i in range(0,inputs.shape[1]):\n",
    "    col = cols[i]\n",
    "    coef = coefs[i]\n",
    "    coef_df_list.append({\"Column\":col,\"Coef\":coef})\n",
    "\n",
    "coef_df = pd.DataFrame(coef_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df.to_csv(\"csv/Coefficients.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
