{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Machine Learning Model Building\n",
    "\n",
    "In this notebook, we'll use the dataset elaborated in the previous step to build several machine learning models, including logistic regression, support vector machine, decision tree, k-nearest neighbor and finally a deep learning model.\n",
    "\n",
    "All of these models will try to classify each match into '0' or '1' depending on who's more likely to win each match based on the match features, player 0 or player 1.\n",
    "\n",
    "Finally, we'll compare these models to see which one is more appropriate in our context, and we'll save only one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import pandas library since we're going to work with csv files and dataframe objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the csv file saved in the last notebook, where we added extra-features to help our model make a better prediction job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"csv/FeatureCalculated_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Player 0</th>\n",
       "      <th>Player 1</th>\n",
       "      <th>Pl0_Rank</th>\n",
       "      <th>Pl1_Rank</th>\n",
       "      <th>Max_Pl0</th>\n",
       "      <th>Max_Pl1</th>\n",
       "      <th>Avg_Pl0</th>\n",
       "      <th>Avg_Pl1</th>\n",
       "      <th>Won</th>\n",
       "      <th>...</th>\n",
       "      <th>The Final</th>\n",
       "      <th>Rank Index</th>\n",
       "      <th>Pl0 Recent Form</th>\n",
       "      <th>Pl0 Form</th>\n",
       "      <th>Pl1 Recent Form</th>\n",
       "      <th>Pl1 Form</th>\n",
       "      <th>Pl0 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl1 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl0 Surface Performance</th>\n",
       "      <th>Pl1 Surface Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>Ljubicic I.</td>\n",
       "      <td>Dosedel S.</td>\n",
       "      <td>77</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0182</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>Enqvist T.</td>\n",
       "      <td>Clement A.</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7614</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>Baccanello P.</td>\n",
       "      <td>Escude N.</td>\n",
       "      <td>655</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.8309</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>Federer R.</td>\n",
       "      <td>Knippschild J.</td>\n",
       "      <td>65</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>Woodbridge T.</td>\n",
       "      <td>Fromberg R.</td>\n",
       "      <td>198</td>\n",
       "      <td>81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.2478</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 146 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Player 0        Player 1  Pl0_Rank  Pl1_Rank  Max_Pl0  \\\n",
       "0  2000-03-01    Ljubicic I.      Dosedel S.        77        63      NaN   \n",
       "1  2000-03-01     Enqvist T.      Clement A.         5        56      NaN   \n",
       "2  2000-03-01  Baccanello P.       Escude N.       655        40      NaN   \n",
       "3  2000-03-01     Federer R.  Knippschild J.        65        87      NaN   \n",
       "4  2000-03-01  Woodbridge T.     Fromberg R.       198        81      NaN   \n",
       "\n",
       "   Max_Pl1  Avg_Pl0  Avg_Pl1  Won  ...  The Final  Rank Index  \\\n",
       "0      NaN      NaN      NaN  1.0  ...          0     -0.0182   \n",
       "1      NaN      NaN      NaN  0.0  ...          0      0.7614   \n",
       "2      NaN      NaN      NaN  1.0  ...          0     -0.8309   \n",
       "3      NaN      NaN      NaN  0.0  ...          0      0.0366   \n",
       "4      NaN      NaN      NaN  1.0  ...          0     -0.2478   \n",
       "\n",
       "   Pl0 Recent Form  Pl0 Form  Pl1 Recent Form  Pl1 Form  \\\n",
       "0             0.43      0.43             0.67      0.67   \n",
       "1             0.57      0.60             0.50      0.50   \n",
       "2             0.00      0.00             0.67      0.67   \n",
       "3             0.71      0.70             0.00      0.00   \n",
       "4             0.50      0.50             0.71      0.62   \n",
       "\n",
       "   Pl0 Perf. vs Similar Opponent  Pl1 Perf. vs Similar Opponent  \\\n",
       "0                           0.66                           0.17   \n",
       "1                           0.58                           0.24   \n",
       "2                           0.00                           0.91   \n",
       "3                           0.90                           0.30   \n",
       "4                           0.29                           0.36   \n",
       "\n",
       "   Pl0 Surface Performance  Pl1 Surface Performance  \n",
       "0                     0.62                     0.40  \n",
       "1                     0.56                     0.51  \n",
       "2                     0.14                     0.64  \n",
       "3                     0.83                     0.10  \n",
       "4                     0.27                     0.46  \n",
       "\n",
       "[5 rows x 146 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before picking up our models, we have to extract the inputs and the targets from this dataset.\n",
    "The target variable is only one, the \"Won\" column.\n",
    "The inputs variables start with the dummy categories we introduced in the preprocessing stage until the last columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date',\n",
       " 'Player 0',\n",
       " 'Player 1',\n",
       " 'Pl0_Rank',\n",
       " 'Pl1_Rank',\n",
       " 'Max_Pl0',\n",
       " 'Max_Pl1',\n",
       " 'Avg_Pl0',\n",
       " 'Avg_Pl1',\n",
       " 'Won',\n",
       " 'Acapulco',\n",
       " 'Adelaide',\n",
       " 'Amersfoort',\n",
       " 'Amsterdam',\n",
       " 'Atlanta',\n",
       " 'Auckland',\n",
       " 'Bangkok',\n",
       " 'Barcelona',\n",
       " 'Basel',\n",
       " 'Bastad',\n",
       " 'Beijing',\n",
       " 'Belgrade',\n",
       " 'Bogota',\n",
       " 'Brighton',\n",
       " 'Brisbane',\n",
       " 'Bucharest',\n",
       " 'Buenos Aires',\n",
       " 'Casablanca',\n",
       " 'Chennai',\n",
       " 'Cincinnati',\n",
       " 'Copenhagen',\n",
       " 'Costa Do Sauipe',\n",
       " 'Delray Beach',\n",
       " 'Doha',\n",
       " 'Dubai',\n",
       " 'Dusseldorf',\n",
       " 'Eastbourne',\n",
       " 'Estoril',\n",
       " 'Geneva',\n",
       " 'Gstaad',\n",
       " 'Halle',\n",
       " 'Hamburg',\n",
       " 'Ho Chi Min City',\n",
       " 'Hong Kong',\n",
       " 'Houston',\n",
       " 'Indian Wells',\n",
       " 'Indianapolis',\n",
       " 'Istanbul',\n",
       " 'Johannesburg',\n",
       " 'Kitzbuhel',\n",
       " 'Kuala Lumpur',\n",
       " 'Las Vegas',\n",
       " 'Lisbon',\n",
       " 'London',\n",
       " 'Long Island',\n",
       " 'Los Angeles',\n",
       " 'Los Cabos',\n",
       " 'Lyon',\n",
       " 'Madrid',\n",
       " 'Mallorca',\n",
       " 'Marrakech',\n",
       " 'Marseille',\n",
       " 'Melbourne',\n",
       " 'Memphis',\n",
       " 'Metz',\n",
       " 'Mexico City',\n",
       " 'Miami',\n",
       " 'Milan',\n",
       " 'Monte Carlo',\n",
       " 'Montpellier',\n",
       " 'Montreal',\n",
       " 'Moscow',\n",
       " 'Mumbai',\n",
       " 'Munich',\n",
       " 'New Haven',\n",
       " 'New York',\n",
       " 'Newport',\n",
       " 'Nice',\n",
       " 'Nottingham',\n",
       " 'Oeiras',\n",
       " 'Orlando',\n",
       " 'Palermo',\n",
       " 'Paris',\n",
       " 'Portschach',\n",
       " 'Queens Club',\n",
       " 'Quito',\n",
       " 'Rio de Janeiro',\n",
       " 'Rome',\n",
       " 'Rotterdam',\n",
       " 'Salvador',\n",
       " 'San Jose',\n",
       " 'San Marino',\n",
       " 'Santiago',\n",
       " 'Sao Paulo',\n",
       " 'Scottsdale',\n",
       " 'Shanghai',\n",
       " 'Shenzhen',\n",
       " 'Sofia',\n",
       " 'Sopot',\n",
       " 'St. Petersburg',\n",
       " 'St. Polten',\n",
       " 'Stockholm',\n",
       " 'Stuttgart',\n",
       " 'Sydney',\n",
       " 'Tashkent',\n",
       " 'Tokyo',\n",
       " 'Toronto',\n",
       " 'Toulouse',\n",
       " 'Umag',\n",
       " 'Valencia',\n",
       " 'Vienna',\n",
       " 'Vina del Mar',\n",
       " 'Warsaw',\n",
       " 'Washington',\n",
       " 'Winston-Salem',\n",
       " 'Zagreb',\n",
       " 's-Hertogenbosch',\n",
       " 'Indoor',\n",
       " 'Outdoor',\n",
       " 'Carpet',\n",
       " 'Clay',\n",
       " 'Grass',\n",
       " 'Hard',\n",
       " 'ATP250',\n",
       " 'ATP500',\n",
       " 'Grand Slam',\n",
       " 'Masters 1000',\n",
       " 'Masters Cup',\n",
       " '0th Round',\n",
       " '1st Round',\n",
       " '2nd Round',\n",
       " '3rd Round',\n",
       " '4th Round',\n",
       " 'Quarterfinals',\n",
       " 'Round Robin',\n",
       " 'Semifinals',\n",
       " 'The Final',\n",
       " 'Rank Index',\n",
       " 'Pl0 Recent Form',\n",
       " 'Pl0 Form',\n",
       " 'Pl1 Recent Form',\n",
       " 'Pl1 Form',\n",
       " 'Pl0 Perf. vs Similar Opponent',\n",
       " 'Pl1 Perf. vs Similar Opponent',\n",
       " 'Pl0 Surface Performance',\n",
       " 'Pl1 Surface Performance']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before splitting our dataset in inputs and targets, we specify a subset of the dataframe containing only matches that are not going to be used in the \"Betting simulation\" stage, so for modeling we're going to pick only matches that don't have information about average and max odds for the players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Player 0</th>\n",
       "      <th>Player 1</th>\n",
       "      <th>Pl0_Rank</th>\n",
       "      <th>Pl1_Rank</th>\n",
       "      <th>Max_Pl0</th>\n",
       "      <th>Max_Pl1</th>\n",
       "      <th>Avg_Pl0</th>\n",
       "      <th>Avg_Pl1</th>\n",
       "      <th>Won</th>\n",
       "      <th>...</th>\n",
       "      <th>The Final</th>\n",
       "      <th>Rank Index</th>\n",
       "      <th>Pl0 Recent Form</th>\n",
       "      <th>Pl0 Form</th>\n",
       "      <th>Pl1 Recent Form</th>\n",
       "      <th>Pl1 Form</th>\n",
       "      <th>Pl0 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl1 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl0 Surface Performance</th>\n",
       "      <th>Pl1 Surface Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>Ljubicic I.</td>\n",
       "      <td>Dosedel S.</td>\n",
       "      <td>77</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0182</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>Enqvist T.</td>\n",
       "      <td>Clement A.</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7614</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>Baccanello P.</td>\n",
       "      <td>Escude N.</td>\n",
       "      <td>655</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.8309</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>Federer R.</td>\n",
       "      <td>Knippschild J.</td>\n",
       "      <td>65</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>Woodbridge T.</td>\n",
       "      <td>Fromberg R.</td>\n",
       "      <td>198</td>\n",
       "      <td>81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.2478</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 146 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Player 0        Player 1  Pl0_Rank  Pl1_Rank  Max_Pl0  \\\n",
       "0  2000-03-01    Ljubicic I.      Dosedel S.        77        63      NaN   \n",
       "1  2000-03-01     Enqvist T.      Clement A.         5        56      NaN   \n",
       "2  2000-03-01  Baccanello P.       Escude N.       655        40      NaN   \n",
       "3  2000-03-01     Federer R.  Knippschild J.        65        87      NaN   \n",
       "4  2000-03-01  Woodbridge T.     Fromberg R.       198        81      NaN   \n",
       "\n",
       "   Max_Pl1  Avg_Pl0  Avg_Pl1  Won  ...  The Final  Rank Index  \\\n",
       "0      NaN      NaN      NaN  1.0  ...          0     -0.0182   \n",
       "1      NaN      NaN      NaN  0.0  ...          0      0.7614   \n",
       "2      NaN      NaN      NaN  1.0  ...          0     -0.8309   \n",
       "3      NaN      NaN      NaN  0.0  ...          0      0.0366   \n",
       "4      NaN      NaN      NaN  1.0  ...          0     -0.2478   \n",
       "\n",
       "   Pl0 Recent Form  Pl0 Form  Pl1 Recent Form  Pl1 Form  \\\n",
       "0             0.43      0.43             0.67      0.67   \n",
       "1             0.57      0.60             0.50      0.50   \n",
       "2             0.00      0.00             0.67      0.67   \n",
       "3             0.71      0.70             0.00      0.00   \n",
       "4             0.50      0.50             0.71      0.62   \n",
       "\n",
       "   Pl0 Perf. vs Similar Opponent  Pl1 Perf. vs Similar Opponent  \\\n",
       "0                           0.66                           0.17   \n",
       "1                           0.58                           0.24   \n",
       "2                           0.00                           0.91   \n",
       "3                           0.90                           0.30   \n",
       "4                           0.29                           0.36   \n",
       "\n",
       "   Pl0 Surface Performance  Pl1 Surface Performance  \n",
       "0                     0.62                     0.40  \n",
       "1                     0.56                     0.51  \n",
       "2                     0.14                     0.64  \n",
       "3                     0.83                     0.10  \n",
       "4                     0.27                     0.46  \n",
       "\n",
       "[5 rows x 146 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nobets_df = df[(df[\"Avg_Pl0\"].isnull()) | (df[\"Avg_Pl1\"].isnull()) | (df[\"Max_Pl0\"].isnull()) | (df[\"Max_Pl1\"].isnull())]\n",
    "nobets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = nobets_df.iloc[:, 10:]\n",
    "targets = nobets_df.iloc[:, 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at \"inputs\" and \"targets\" content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acapulco</th>\n",
       "      <th>Adelaide</th>\n",
       "      <th>Amersfoort</th>\n",
       "      <th>Amsterdam</th>\n",
       "      <th>Atlanta</th>\n",
       "      <th>Auckland</th>\n",
       "      <th>Bangkok</th>\n",
       "      <th>Barcelona</th>\n",
       "      <th>Basel</th>\n",
       "      <th>Bastad</th>\n",
       "      <th>...</th>\n",
       "      <th>The Final</th>\n",
       "      <th>Rank Index</th>\n",
       "      <th>Pl0 Recent Form</th>\n",
       "      <th>Pl0 Form</th>\n",
       "      <th>Pl1 Recent Form</th>\n",
       "      <th>Pl1 Form</th>\n",
       "      <th>Pl0 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl1 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl0 Surface Performance</th>\n",
       "      <th>Pl1 Surface Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0182</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7614</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.8309</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.2478</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Acapulco  Adelaide  Amersfoort  Amsterdam  Atlanta  Auckland  Bangkok  \\\n",
       "0         0         1           0          0        0         0        0   \n",
       "1         0         1           0          0        0         0        0   \n",
       "2         0         1           0          0        0         0        0   \n",
       "3         0         1           0          0        0         0        0   \n",
       "4         0         1           0          0        0         0        0   \n",
       "\n",
       "   Barcelona  Basel  Bastad  ...  The Final  Rank Index  Pl0 Recent Form  \\\n",
       "0          0      0       0  ...          0     -0.0182             0.43   \n",
       "1          0      0       0  ...          0      0.7614             0.57   \n",
       "2          0      0       0  ...          0     -0.8309             0.00   \n",
       "3          0      0       0  ...          0      0.0366             0.71   \n",
       "4          0      0       0  ...          0     -0.2478             0.50   \n",
       "\n",
       "   Pl0 Form  Pl1 Recent Form  Pl1 Form  Pl0 Perf. vs Similar Opponent  \\\n",
       "0      0.43             0.67      0.67                           0.66   \n",
       "1      0.60             0.50      0.50                           0.58   \n",
       "2      0.00             0.67      0.67                           0.00   \n",
       "3      0.70             0.00      0.00                           0.90   \n",
       "4      0.50             0.71      0.62                           0.29   \n",
       "\n",
       "   Pl1 Perf. vs Similar Opponent  Pl0 Surface Performance  \\\n",
       "0                           0.17                     0.62   \n",
       "1                           0.24                     0.56   \n",
       "2                           0.91                     0.14   \n",
       "3                           0.30                     0.83   \n",
       "4                           0.36                     0.27   \n",
       "\n",
       "   Pl1 Surface Performance  \n",
       "0                     0.40  \n",
       "1                     0.51  \n",
       "2                     0.64  \n",
       "3                     0.10  \n",
       "4                     0.46  \n",
       "\n",
       "[5 rows x 136 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    0.0\n",
       "2    1.0\n",
       "3    0.0\n",
       "4    1.0\n",
       "Name: Won, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to split the data into training and testing data.\n",
    "We'll use a 75:25 split, and since we assume each match is independent from the others, we won't shuffle the data randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(inputs, targets, test_size=0.25, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Let's start off with the logistic regression, and see how accurately predicts winners and losers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lreg = LogisticRegression(max_iter=10000, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=2,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lreg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7174766481656965\n"
     ]
    }
   ],
   "source": [
    "score = lreg.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression predicts correctly more than 7 matches out of 10!\n",
    "\n",
    "Since we structured our data to have as many '0' targets than '1' targets, a random model would have approximately 50% accuracy.\n",
    "Jumping from 50% to almost 72% is definetely a good result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "Another popular classifier model is the SVM, Support Vector Machine.\n",
    "Let's see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(kernel = 'rbf')\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7188303776905375\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM model has a 0.718 accuracy, very similar to the Logistic Regression model!\n",
    "Let's see if we can find better models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier\n",
    "\n",
    "Let's try out the Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6409909300121835\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Decision Tree model, as we can see, is not a very good choice. It returns only a 0.64 prediction accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors\n",
    "\n",
    "Let's see if the KNN model can do a better job than the Logistic Regression and the SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the KNN model we have to pick the right K value, so we're going to fit our model with several values from 1 to 8, and we'll compare the errors of each run.\n",
    "Finally, we'll run the model with the appropriate K value and check its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = []\n",
    "\n",
    "# Calculating error for K values between 1 and 8\n",
    "for i in range(1, 9):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(x_train, y_train)\n",
    "    pred_i = knn.predict(x_test)\n",
    "    error.append(np.mean(pred_i != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Mean Error')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, 9), error, color='red', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='blue', markersize=10)\n",
    "plt.title('Error Rate K Value')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('Mean Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the plot above, we obtain the lowest error with K = 8, so let's use 8 as K parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=8, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=8)\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.76      0.69      3688\n",
      "         1.0       0.70      0.57      0.63      3699\n",
      "\n",
      "    accuracy                           0.66      7387\n",
      "   macro avg       0.67      0.66      0.66      7387\n",
      "weighted avg       0.67      0.66      0.66      7387\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN accuracy is around 0.66 / 0.67, so not that great.\n",
    "Let's try Neural Networks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Networks\n",
    "\n",
    "Finally, let's see if we can build a neural network that can achieve a greater accuracy than the Logistic Regression and SVM models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = inputs.shape[1]\n",
    "\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(1000, input_dim=input_cols, activation='relu'))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(60, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dense(7, activation='relu'))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "22161/22161 [==============================] - 5s 239us/step - loss: 0.6385 - accuracy: 0.66020s - loss: 0.6411 - accura\n",
      "Epoch 2/10\n",
      "22161/22161 [==============================] - 5s 224us/step - loss: 0.6114 - accuracy: 0.6930\n",
      "Epoch 3/10\n",
      "22161/22161 [==============================] - 6s 264us/step - loss: 0.5997 - accuracy: 0.6981\n",
      "Epoch 4/10\n",
      "22161/22161 [==============================] - 6s 257us/step - loss: 0.5900 - accuracy: 0.69790s - loss: 0.5904 - accuracy: 0.\n",
      "Epoch 5/10\n",
      "22161/22161 [==============================] - 6s 263us/step - loss: 0.5820 - accuracy: 0.7038\n",
      "Epoch 6/10\n",
      "22161/22161 [==============================] - 6s 271us/step - loss: 0.5752 - accuracy: 0.7069\n",
      "Epoch 7/10\n",
      "22161/22161 [==============================] - 6s 274us/step - loss: 0.5713 - accuracy: 0.7086\n",
      "Epoch 8/10\n",
      "22161/22161 [==============================] - 6s 255us/step - loss: 0.5663 - accuracy: 0.7096\n",
      "Epoch 9/10\n",
      "22161/22161 [==============================] - 6s 277us/step - loss: 0.5631 - accuracy: 0.7095\n",
      "Epoch 10/10\n",
      "22161/22161 [==============================] - 7s 303us/step - loss: 0.5563 - accuracy: 0.7123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1f410cab3c8>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7387/7387 [==============================] - 1s 162us/step\n",
      "Test accuracy: 0.7017734050750732\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we achieved around 0.701 accuracy, almost enough to beat the Logistic Regression model.\n",
    "\n",
    "However, we'll decide to make use of the Logistic Regression model since we can predicts probabilities that each player has to win the match!\n",
    "\n",
    "In this way, we can define the \"predicted\" odds for any given match calculating the logistic regression formula on the inputs features.\n",
    "\n",
    "So let's save our Logistic Regression model, we're going to use it in the next notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'logistic_regression.lr'\n",
    "pickle.dump(lreg, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have saved our model, let's create a coefficients dataframe, so that we associate each input column with the appropriate weight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(inputs.columns)\n",
    "coefs = lreg.coef_.tolist()[0]\n",
    "\n",
    "coef_df_list = []\n",
    "for i in range(0,inputs.shape[1]):\n",
    "    col = cols[i]\n",
    "    coef = coefs[i]\n",
    "    coef_df_list.append({\"Column\":col,\"Coef\":coef})\n",
    "\n",
    "coef_df = pd.DataFrame(coef_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df.to_csv(\"csv/Coefficients.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
