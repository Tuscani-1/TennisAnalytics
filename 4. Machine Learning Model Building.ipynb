{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Machine Learning Model Building\n",
    "\n",
    "In this notebook, we'll use the dataset elaborated in the previous step to build several machine learning models, including logistic regression, support vector machine, decision tree, k-nearest neighbor and finally a deep learning model.\n",
    "\n",
    "All of these models will try to classify each match into '0' or '1' depending on who's more likely to win each match based on the match features, player 0 or player 1.\n",
    "\n",
    "Finally, we'll compare these models to see which one is more appropriate in our context, and we'll save only one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import pandas library since we're going to work with csv files and dataframe objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the csv file saved in the last notebook, where we added extra-features to help our model make a better prediction job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"csv/FeatureCalculated_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Player 0</th>\n",
       "      <th>Player 1</th>\n",
       "      <th>Pl0_Rank</th>\n",
       "      <th>Pl1_Rank</th>\n",
       "      <th>Max_Pl0</th>\n",
       "      <th>Max_Pl1</th>\n",
       "      <th>Avg_Pl0</th>\n",
       "      <th>Avg_Pl1</th>\n",
       "      <th>Won</th>\n",
       "      <th>...</th>\n",
       "      <th>The Final</th>\n",
       "      <th>Rank Index</th>\n",
       "      <th>Pl0 Recent Form</th>\n",
       "      <th>Pl0 Form</th>\n",
       "      <th>Pl1 Recent Form</th>\n",
       "      <th>Pl1 Form</th>\n",
       "      <th>Pl0 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl1 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl0 Surface Performance</th>\n",
       "      <th>Pl1 Surface Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>Ljubicic I.</td>\n",
       "      <td>Dosedel S.</td>\n",
       "      <td>77</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0182</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>Enqvist T.</td>\n",
       "      <td>Clement A.</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7614</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>Baccanello P.</td>\n",
       "      <td>Escude N.</td>\n",
       "      <td>655</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.8309</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>Federer R.</td>\n",
       "      <td>Knippschild J.</td>\n",
       "      <td>65</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>Woodbridge T.</td>\n",
       "      <td>Fromberg R.</td>\n",
       "      <td>198</td>\n",
       "      <td>81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.2478</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Player 0        Player 1  Pl0_Rank  Pl1_Rank  Max_Pl0  \\\n",
       "0  2000-03-01    Ljubicic I.      Dosedel S.        77        63      NaN   \n",
       "1  2000-03-01     Enqvist T.      Clement A.         5        56      NaN   \n",
       "2  2000-03-01  Baccanello P.       Escude N.       655        40      NaN   \n",
       "3  2000-03-01     Federer R.  Knippschild J.        65        87      NaN   \n",
       "4  2000-03-01  Woodbridge T.     Fromberg R.       198        81      NaN   \n",
       "\n",
       "   Max_Pl1  Avg_Pl0  Avg_Pl1  Won  ...  The Final  Rank Index  \\\n",
       "0      NaN      NaN      NaN  1.0  ...          0     -0.0182   \n",
       "1      NaN      NaN      NaN  0.0  ...          0      0.7614   \n",
       "2      NaN      NaN      NaN  1.0  ...          0     -0.8309   \n",
       "3      NaN      NaN      NaN  0.0  ...          0      0.0366   \n",
       "4      NaN      NaN      NaN  1.0  ...          0     -0.2478   \n",
       "\n",
       "   Pl0 Recent Form  Pl0 Form  Pl1 Recent Form  Pl1 Form  \\\n",
       "0             0.43      0.43             0.67      0.67   \n",
       "1             0.57      0.60             0.50      0.50   \n",
       "2             0.00      0.00             0.67      0.67   \n",
       "3             0.71      0.70             0.00      0.00   \n",
       "4             0.50      0.50             0.71      0.62   \n",
       "\n",
       "   Pl0 Perf. vs Similar Opponent  Pl1 Perf. vs Similar Opponent  \\\n",
       "0                           0.66                           0.17   \n",
       "1                           0.58                           0.24   \n",
       "2                           0.00                           0.91   \n",
       "3                           0.90                           0.30   \n",
       "4                           0.29                           0.36   \n",
       "\n",
       "   Pl0 Surface Performance  Pl1 Surface Performance  \n",
       "0                     0.62                     0.40  \n",
       "1                     0.56                     0.51  \n",
       "2                     0.14                     0.64  \n",
       "3                     0.83                     0.10  \n",
       "4                     0.27                     0.46  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before picking up our models, we have to extract the inputs and the targets from this dataset.\n",
    "The target variable is only one, the \"Won\" column.\n",
    "The inputs variables start with the dummy categories we introduced in the preprocessing stage until the last columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date',\n",
       " 'Player 0',\n",
       " 'Player 1',\n",
       " 'Pl0_Rank',\n",
       " 'Pl1_Rank',\n",
       " 'Max_Pl0',\n",
       " 'Max_Pl1',\n",
       " 'Avg_Pl0',\n",
       " 'Avg_Pl1',\n",
       " 'Won',\n",
       " 'Indoor',\n",
       " 'Outdoor',\n",
       " 'Carpet',\n",
       " 'Clay',\n",
       " 'Grass',\n",
       " 'Hard',\n",
       " 'ATP250',\n",
       " 'ATP500',\n",
       " 'Grand Slam',\n",
       " 'Masters 1000',\n",
       " 'Masters Cup',\n",
       " '0th Round',\n",
       " '1st Round',\n",
       " '2nd Round',\n",
       " '3rd Round',\n",
       " '4th Round',\n",
       " 'Quarterfinals',\n",
       " 'Round Robin',\n",
       " 'Semifinals',\n",
       " 'The Final',\n",
       " 'Rank Index',\n",
       " 'Pl0 Recent Form',\n",
       " 'Pl0 Form',\n",
       " 'Pl1 Recent Form',\n",
       " 'Pl1 Form',\n",
       " 'Pl0 Perf. vs Similar Opponent',\n",
       " 'Pl1 Perf. vs Similar Opponent',\n",
       " 'Pl0 Surface Performance',\n",
       " 'Pl1 Surface Performance']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before splitting our dataset in inputs and targets, we specify a subset of the dataframe containing only matches that are not going to be used in the \"Betting simulation\" stage, so for modeling we're going to pick only matches that don't have information about average and max odds for the players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Player 0</th>\n",
       "      <th>Player 1</th>\n",
       "      <th>Pl0_Rank</th>\n",
       "      <th>Pl1_Rank</th>\n",
       "      <th>Max_Pl0</th>\n",
       "      <th>Max_Pl1</th>\n",
       "      <th>Avg_Pl0</th>\n",
       "      <th>Avg_Pl1</th>\n",
       "      <th>Won</th>\n",
       "      <th>...</th>\n",
       "      <th>The Final</th>\n",
       "      <th>Rank Index</th>\n",
       "      <th>Pl0 Recent Form</th>\n",
       "      <th>Pl0 Form</th>\n",
       "      <th>Pl1 Recent Form</th>\n",
       "      <th>Pl1 Form</th>\n",
       "      <th>Pl0 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl1 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl0 Surface Performance</th>\n",
       "      <th>Pl1 Surface Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>Ljubicic I.</td>\n",
       "      <td>Dosedel S.</td>\n",
       "      <td>77</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0182</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>Enqvist T.</td>\n",
       "      <td>Clement A.</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7614</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>Baccanello P.</td>\n",
       "      <td>Escude N.</td>\n",
       "      <td>655</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.8309</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>Federer R.</td>\n",
       "      <td>Knippschild J.</td>\n",
       "      <td>65</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>Woodbridge T.</td>\n",
       "      <td>Fromberg R.</td>\n",
       "      <td>198</td>\n",
       "      <td>81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.2478</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Player 0        Player 1  Pl0_Rank  Pl1_Rank  Max_Pl0  \\\n",
       "0  2000-03-01    Ljubicic I.      Dosedel S.        77        63      NaN   \n",
       "1  2000-03-01     Enqvist T.      Clement A.         5        56      NaN   \n",
       "2  2000-03-01  Baccanello P.       Escude N.       655        40      NaN   \n",
       "3  2000-03-01     Federer R.  Knippschild J.        65        87      NaN   \n",
       "4  2000-03-01  Woodbridge T.     Fromberg R.       198        81      NaN   \n",
       "\n",
       "   Max_Pl1  Avg_Pl0  Avg_Pl1  Won  ...  The Final  Rank Index  \\\n",
       "0      NaN      NaN      NaN  1.0  ...          0     -0.0182   \n",
       "1      NaN      NaN      NaN  0.0  ...          0      0.7614   \n",
       "2      NaN      NaN      NaN  1.0  ...          0     -0.8309   \n",
       "3      NaN      NaN      NaN  0.0  ...          0      0.0366   \n",
       "4      NaN      NaN      NaN  1.0  ...          0     -0.2478   \n",
       "\n",
       "   Pl0 Recent Form  Pl0 Form  Pl1 Recent Form  Pl1 Form  \\\n",
       "0             0.43      0.43             0.67      0.67   \n",
       "1             0.57      0.60             0.50      0.50   \n",
       "2             0.00      0.00             0.67      0.67   \n",
       "3             0.71      0.70             0.00      0.00   \n",
       "4             0.50      0.50             0.71      0.62   \n",
       "\n",
       "   Pl0 Perf. vs Similar Opponent  Pl1 Perf. vs Similar Opponent  \\\n",
       "0                           0.66                           0.17   \n",
       "1                           0.58                           0.24   \n",
       "2                           0.00                           0.91   \n",
       "3                           0.90                           0.30   \n",
       "4                           0.29                           0.36   \n",
       "\n",
       "   Pl0 Surface Performance  Pl1 Surface Performance  \n",
       "0                     0.62                     0.40  \n",
       "1                     0.56                     0.51  \n",
       "2                     0.14                     0.64  \n",
       "3                     0.83                     0.10  \n",
       "4                     0.27                     0.46  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nobets_df = df[(df[\"Avg_Pl0\"].isnull()) | (df[\"Avg_Pl1\"].isnull()) | (df[\"Max_Pl0\"].isnull()) | (df[\"Max_Pl1\"].isnull())]\n",
    "nobets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = nobets_df.iloc[:, 10:]\n",
    "targets = nobets_df.iloc[:, 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at \"inputs\" and \"targets\" content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Indoor</th>\n",
       "      <th>Outdoor</th>\n",
       "      <th>Carpet</th>\n",
       "      <th>Clay</th>\n",
       "      <th>Grass</th>\n",
       "      <th>Hard</th>\n",
       "      <th>ATP250</th>\n",
       "      <th>ATP500</th>\n",
       "      <th>Grand Slam</th>\n",
       "      <th>Masters 1000</th>\n",
       "      <th>...</th>\n",
       "      <th>The Final</th>\n",
       "      <th>Rank Index</th>\n",
       "      <th>Pl0 Recent Form</th>\n",
       "      <th>Pl0 Form</th>\n",
       "      <th>Pl1 Recent Form</th>\n",
       "      <th>Pl1 Form</th>\n",
       "      <th>Pl0 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl1 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl0 Surface Performance</th>\n",
       "      <th>Pl1 Surface Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0182</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7614</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.8309</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.2478</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Indoor  Outdoor  Carpet  Clay  Grass  Hard  ATP250  ATP500  Grand Slam  \\\n",
       "0       0        1       0     0      0     1       1       0           0   \n",
       "1       0        1       0     0      0     1       1       0           0   \n",
       "2       0        1       0     0      0     1       1       0           0   \n",
       "3       0        1       0     0      0     1       1       0           0   \n",
       "4       0        1       0     0      0     1       1       0           0   \n",
       "\n",
       "   Masters 1000  ...  The Final  Rank Index  Pl0 Recent Form  Pl0 Form  \\\n",
       "0             0  ...          0     -0.0182             0.43      0.43   \n",
       "1             0  ...          0      0.7614             0.57      0.60   \n",
       "2             0  ...          0     -0.8309             0.00      0.00   \n",
       "3             0  ...          0      0.0366             0.71      0.70   \n",
       "4             0  ...          0     -0.2478             0.50      0.50   \n",
       "\n",
       "   Pl1 Recent Form  Pl1 Form  Pl0 Perf. vs Similar Opponent  \\\n",
       "0             0.67      0.67                           0.66   \n",
       "1             0.50      0.50                           0.58   \n",
       "2             0.67      0.67                           0.00   \n",
       "3             0.00      0.00                           0.90   \n",
       "4             0.71      0.62                           0.29   \n",
       "\n",
       "   Pl1 Perf. vs Similar Opponent  Pl0 Surface Performance  \\\n",
       "0                           0.17                     0.62   \n",
       "1                           0.24                     0.56   \n",
       "2                           0.91                     0.14   \n",
       "3                           0.30                     0.83   \n",
       "4                           0.36                     0.27   \n",
       "\n",
       "   Pl1 Surface Performance  \n",
       "0                     0.40  \n",
       "1                     0.51  \n",
       "2                     0.64  \n",
       "3                     0.10  \n",
       "4                     0.46  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    0.0\n",
       "2    1.0\n",
       "3    0.0\n",
       "4    1.0\n",
       "Name: Won, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to split the data into training and testing data.\n",
    "We'll use a 75:25 split, and since we assume each match is independent from the others, we won't shuffle the data randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(inputs, targets, test_size=0.25, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Let's start off with the logistic regression, and see how accurately predicts winners and losers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lreg = LogisticRegression(max_iter=10000, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=2,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lreg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7205902260728306\n"
     ]
    }
   ],
   "source": [
    "score = lreg.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression predicts correctly more than 7 matches out of 10!\n",
    "\n",
    "Since we structured our data to have as many '0' targets than '1' targets, a random model would have approximately 50% accuracy.\n",
    "Jumping from 50% to above 72% is definetely a good result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "Another popular classifier model is the SVM, Support Vector Machine.\n",
    "Let's see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(kernel = 'rbf')\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7205902260728306\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM model has a 0.72 accuracy, just like the Logistic Regression model!\n",
    "Let's see if we can find better models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier\n",
    "\n",
    "Let's try out the Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6297549749560037\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Decision Tree model, as we can see, is not a very good choice. It returns only a 0.62 prediction accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors\n",
    "\n",
    "Let's see if the KNN model can do a better job than the Logistic Regression and the SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the KNN model we have to pick the right K value, so we're going to fit our model with several values from 1 to 8, and we'll compare the errors of each run.\n",
    "Finally, we'll run the model with the appropriate K value and check its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = []\n",
    "\n",
    "# Calculating error for K values between 1 and 8\n",
    "for i in range(1, 9):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(x_train, y_train)\n",
    "    pred_i = knn.predict(x_test)\n",
    "    error.append(np.mean(pred_i != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Mean Error')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, 9), error, color='red', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='blue', markersize=10)\n",
    "plt.title('Error Rate K Value')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('Mean Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the plot above, we obtain the lowest error with K = 7, so let's use 7 as K parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=7)\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.67      0.67      3688\n",
      "         1.0       0.67      0.67      0.67      3699\n",
      "\n",
      "    accuracy                           0.67      7387\n",
      "   macro avg       0.67      0.67      0.67      7387\n",
      "weighted avg       0.67      0.67      0.67      7387\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN accuracy is around 0.67, so not that great.\n",
    "Let's try Neural Networks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Networks\n",
    "\n",
    "Finally, let's see if we can build a neural network that can achieve a greater accuracy than the Logistic Regression and SVM models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = inputs.shape[1]\n",
    "\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(1000, input_dim=input_cols, activation='relu'))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(60, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dense(7, activation='relu'))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "22161/22161 [==============================] - 4s 181us/step - loss: 0.6121 - accuracy: 0.6654\n",
      "Epoch 2/10\n",
      "22161/22161 [==============================] - 4s 170us/step - loss: 0.5622 - accuracy: 0.7008\n",
      "Epoch 3/10\n",
      "22161/22161 [==============================] - 4s 164us/step - loss: 0.5508 - accuracy: 0.7037\n",
      "Epoch 4/10\n",
      "22161/22161 [==============================] - 4s 187us/step - loss: 0.5486 - accuracy: 0.7066\n",
      "Epoch 5/10\n",
      "22161/22161 [==============================] - 4s 181us/step - loss: 0.5484 - accuracy: 0.7052\n",
      "Epoch 6/10\n",
      "22161/22161 [==============================] - 4s 186us/step - loss: 0.5445 - accuracy: 0.7069\n",
      "Epoch 7/10\n",
      "22161/22161 [==============================] - 4s 180us/step - loss: 0.5455 - accuracy: 0.7049\n",
      "Epoch 8/10\n",
      "22161/22161 [==============================] - 4s 182us/step - loss: 0.5412 - accuracy: 0.7091\n",
      "Epoch 9/10\n",
      "22161/22161 [==============================] - 4s 190us/step - loss: 0.5403 - accuracy: 0.7077\n",
      "Epoch 10/10\n",
      "22161/22161 [==============================] - 4s 188us/step - loss: 0.5413 - accuracy: 0.70641s - loss: 0.541\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1aa3d9f36c8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7387/7387 [==============================] - 1s 97us/step\n",
      "Test accuracy: 0.7203195095062256\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we achieved 0.72 accuracy, just like the Logistic Regression and SVM models.\n",
    "\n",
    "However, we'll decide to make use of the Logistic Regression model since we can predicts probabilities that each player has to win the match!\n",
    "\n",
    "In this way, we can define the \"predicted\" odds for any given match calculating the logistic regression formula on the inputs features.\n",
    "\n",
    "So let's save our Logistic Regression model, we're going to use it in the next notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'logistic_regression.lr'\n",
    "pickle.dump(lreg, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have saved our model, let's create a coefficients dataframe, so that we associate each input column with the appropriate weight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(inputs.columns)\n",
    "coefs = lreg.coef_.tolist()[0]\n",
    "\n",
    "coef_df_list = []\n",
    "for i in range(0,inputs.shape[1]):\n",
    "    col = cols[i]\n",
    "    coef = coefs[i]\n",
    "    coef_df_list.append({\"Column\":col,\"Coef\":coef})\n",
    "\n",
    "coef_df = pd.DataFrame(coef_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df.to_csv(\"csv/Coefficients.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
