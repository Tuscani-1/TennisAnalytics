{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Machine Learning Model Building\n",
    "\n",
    "In this notebook, we'll use the dataset elaborated in the previous step to build several machine learning models, including logistic regression, support vector machine, decision tree, k-nearest neighbor and finally a deep learning model.\n",
    "\n",
    "All of these models will try to classify each match into '0' or '1' depending on who's more likely to win each match based on the match features, player 0 or player 1.\n",
    "\n",
    "Finally, we'll compare these models to see which one is more appropriate in our context, and we'll save only one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import pandas library since we're going to work with csv files and dataframe objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the csv file saved in the last notebook, where we added extra-features to help our model make a better prediction job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"csv/FeatureCalculated_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Player 0</th>\n",
       "      <th>Player 1</th>\n",
       "      <th>Won</th>\n",
       "      <th>Pl0_Rank</th>\n",
       "      <th>Pl1_Rank</th>\n",
       "      <th>Avg_Pl0</th>\n",
       "      <th>Avg_Pl1</th>\n",
       "      <th>Max_Pl1</th>\n",
       "      <th>Max_Pl0</th>\n",
       "      <th>...</th>\n",
       "      <th>Pl0 Recent Form</th>\n",
       "      <th>Pl0 Form</th>\n",
       "      <th>Pl1 Recent Form</th>\n",
       "      <th>Pl1 Form</th>\n",
       "      <th>Pl0 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl1 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl0 Surface Performance</th>\n",
       "      <th>Pl1 Surface Performance</th>\n",
       "      <th>H2H Index</th>\n",
       "      <th>Exp Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>Ljubicic I.</td>\n",
       "      <td>Dosedel S.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>Enqvist T.</td>\n",
       "      <td>Clement A.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>Baccanello P.</td>\n",
       "      <td>Escude N.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>655</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>Federer R.</td>\n",
       "      <td>Knippschild J.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>Woodbridge T.</td>\n",
       "      <td>Fromberg R.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>198</td>\n",
       "      <td>81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Player 0        Player 1  Won  Pl0_Rank  Pl1_Rank  \\\n",
       "0  2000-01-03    Ljubicic I.      Dosedel S.  1.0        77        63   \n",
       "1  2000-01-03     Enqvist T.      Clement A.  0.0         5        56   \n",
       "2  2000-01-03  Baccanello P.       Escude N.  1.0       655        40   \n",
       "3  2000-01-03     Federer R.  Knippschild J.  0.0        65        87   \n",
       "4  2000-01-03  Woodbridge T.     Fromberg R.  1.0       198        81   \n",
       "\n",
       "   Avg_Pl0  Avg_Pl1  Max_Pl1  Max_Pl0  ...  Pl0 Recent Form  Pl0 Form  \\\n",
       "0      NaN      NaN      NaN      NaN  ...              0.0       0.0   \n",
       "1      NaN      NaN      NaN      NaN  ...              0.0       0.0   \n",
       "2      NaN      NaN      NaN      NaN  ...              0.0       0.0   \n",
       "3      NaN      NaN      NaN      NaN  ...              0.0       0.0   \n",
       "4      NaN      NaN      NaN      NaN  ...              0.0       0.0   \n",
       "\n",
       "   Pl1 Recent Form  Pl1 Form  Pl0 Perf. vs Similar Opponent  \\\n",
       "0              0.0       0.0                           0.66   \n",
       "1              0.0       0.0                           0.58   \n",
       "2              0.0       0.0                           0.00   \n",
       "3              0.0       0.0                           0.90   \n",
       "4              0.0       0.0                           0.29   \n",
       "\n",
       "   Pl1 Perf. vs Similar Opponent  Pl0 Surface Performance  \\\n",
       "0                           0.17                     0.61   \n",
       "1                           0.24                     0.56   \n",
       "2                           0.91                     0.14   \n",
       "3                           0.30                     0.84   \n",
       "4                           0.36                     0.27   \n",
       "\n",
       "   Pl1 Surface Performance  H2H Index  Exp Index  \n",
       "0                     0.40        0.0        0.0  \n",
       "1                     0.51        0.0        0.0  \n",
       "2                     0.65        0.0        0.0  \n",
       "3                     0.10        0.0        0.0  \n",
       "4                     0.46        0.0        0.0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before picking up our models, we have to extract the inputs and the targets from this dataset.\n",
    "The target variable is only one, the \"Won\" column.\n",
    "The inputs variables start with the dummy categories we introduced in the preprocessing stage until the last columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date',\n",
       " 'Player 0',\n",
       " 'Player 1',\n",
       " 'Won',\n",
       " 'Pl0_Rank',\n",
       " 'Pl1_Rank',\n",
       " 'Avg_Pl0',\n",
       " 'Avg_Pl1',\n",
       " 'Max_Pl1',\n",
       " 'Max_Pl0',\n",
       " 'PS_Pl0',\n",
       " 'PS_Pl1',\n",
       " 'B365_Pl0',\n",
       " 'B365_Pl1',\n",
       " 'Indoor',\n",
       " 'Outdoor',\n",
       " 'Carpet',\n",
       " 'Clay',\n",
       " 'Grass',\n",
       " 'Hard',\n",
       " 'ATP250',\n",
       " 'ATP500',\n",
       " 'Grand Slam',\n",
       " 'Masters 1000',\n",
       " 'Masters Cup',\n",
       " '1st Round',\n",
       " '2nd Round',\n",
       " '3rd Round',\n",
       " '4th Round',\n",
       " 'Quarterfinals',\n",
       " 'Round Robin',\n",
       " 'Semifinals',\n",
       " 'The Final',\n",
       " 'Rank Index',\n",
       " 'Pl0 Recent Form',\n",
       " 'Pl0 Form',\n",
       " 'Pl1 Recent Form',\n",
       " 'Pl1 Form',\n",
       " 'Pl0 Perf. vs Similar Opponent',\n",
       " 'Pl1 Perf. vs Similar Opponent',\n",
       " 'Pl0 Surface Performance',\n",
       " 'Pl1 Surface Performance',\n",
       " 'H2H Index',\n",
       " 'Exp Index']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before splitting our dataset in inputs and targets, we specify a subset of the dataframe containing only matches that are not going to be used in the \"Betting simulation\" stage, so for modeling we're going to pick only matches that don't have information about average and max odds for the players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Player 0</th>\n",
       "      <th>Player 1</th>\n",
       "      <th>Won</th>\n",
       "      <th>Pl0_Rank</th>\n",
       "      <th>Pl1_Rank</th>\n",
       "      <th>Avg_Pl0</th>\n",
       "      <th>Avg_Pl1</th>\n",
       "      <th>Max_Pl1</th>\n",
       "      <th>Max_Pl0</th>\n",
       "      <th>...</th>\n",
       "      <th>Pl0 Recent Form</th>\n",
       "      <th>Pl0 Form</th>\n",
       "      <th>Pl1 Recent Form</th>\n",
       "      <th>Pl1 Form</th>\n",
       "      <th>Pl0 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl1 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl0 Surface Performance</th>\n",
       "      <th>Pl1 Surface Performance</th>\n",
       "      <th>H2H Index</th>\n",
       "      <th>Exp Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>Ljubicic I.</td>\n",
       "      <td>Dosedel S.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>Enqvist T.</td>\n",
       "      <td>Clement A.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>Baccanello P.</td>\n",
       "      <td>Escude N.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>655</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>Federer R.</td>\n",
       "      <td>Knippschild J.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>Woodbridge T.</td>\n",
       "      <td>Fromberg R.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>198</td>\n",
       "      <td>81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Player 0        Player 1  Won  Pl0_Rank  Pl1_Rank  \\\n",
       "0  2000-01-03    Ljubicic I.      Dosedel S.  1.0        77        63   \n",
       "1  2000-01-03     Enqvist T.      Clement A.  0.0         5        56   \n",
       "2  2000-01-03  Baccanello P.       Escude N.  1.0       655        40   \n",
       "3  2000-01-03     Federer R.  Knippschild J.  0.0        65        87   \n",
       "4  2000-01-03  Woodbridge T.     Fromberg R.  1.0       198        81   \n",
       "\n",
       "   Avg_Pl0  Avg_Pl1  Max_Pl1  Max_Pl0  ...  Pl0 Recent Form  Pl0 Form  \\\n",
       "0      NaN      NaN      NaN      NaN  ...              0.0       0.0   \n",
       "1      NaN      NaN      NaN      NaN  ...              0.0       0.0   \n",
       "2      NaN      NaN      NaN      NaN  ...              0.0       0.0   \n",
       "3      NaN      NaN      NaN      NaN  ...              0.0       0.0   \n",
       "4      NaN      NaN      NaN      NaN  ...              0.0       0.0   \n",
       "\n",
       "   Pl1 Recent Form  Pl1 Form  Pl0 Perf. vs Similar Opponent  \\\n",
       "0              0.0       0.0                           0.66   \n",
       "1              0.0       0.0                           0.58   \n",
       "2              0.0       0.0                           0.00   \n",
       "3              0.0       0.0                           0.90   \n",
       "4              0.0       0.0                           0.29   \n",
       "\n",
       "   Pl1 Perf. vs Similar Opponent  Pl0 Surface Performance  \\\n",
       "0                           0.17                     0.61   \n",
       "1                           0.24                     0.56   \n",
       "2                           0.91                     0.14   \n",
       "3                           0.30                     0.84   \n",
       "4                           0.36                     0.27   \n",
       "\n",
       "   Pl1 Surface Performance  H2H Index  Exp Index  \n",
       "0                     0.40        0.0        0.0  \n",
       "1                     0.51        0.0        0.0  \n",
       "2                     0.65        0.0        0.0  \n",
       "3                     0.10        0.0        0.0  \n",
       "4                     0.46        0.0        0.0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nobets_df = df[(df[\"Avg_Pl0\"].isnull()) | (df[\"Avg_Pl1\"].isnull()) | (df[\"Max_Pl0\"].isnull()) | (df[\"Max_Pl1\"].isnull())]\n",
    "nobets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = nobets_df.iloc[:, 14:]\n",
    "targets = nobets_df.iloc[:, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at \"inputs\" and \"targets\" content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Indoor</th>\n",
       "      <th>Outdoor</th>\n",
       "      <th>Carpet</th>\n",
       "      <th>Clay</th>\n",
       "      <th>Grass</th>\n",
       "      <th>Hard</th>\n",
       "      <th>ATP250</th>\n",
       "      <th>ATP500</th>\n",
       "      <th>Grand Slam</th>\n",
       "      <th>Masters 1000</th>\n",
       "      <th>...</th>\n",
       "      <th>Pl0 Recent Form</th>\n",
       "      <th>Pl0 Form</th>\n",
       "      <th>Pl1 Recent Form</th>\n",
       "      <th>Pl1 Form</th>\n",
       "      <th>Pl0 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl1 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl0 Surface Performance</th>\n",
       "      <th>Pl1 Surface Performance</th>\n",
       "      <th>H2H Index</th>\n",
       "      <th>Exp Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Indoor  Outdoor  Carpet  Clay  Grass  Hard  ATP250  ATP500  Grand Slam  \\\n",
       "0       0        1       0     0      0     1       1       0           0   \n",
       "1       0        1       0     0      0     1       1       0           0   \n",
       "2       0        1       0     0      0     1       1       0           0   \n",
       "3       0        1       0     0      0     1       1       0           0   \n",
       "4       0        1       0     0      0     1       1       0           0   \n",
       "\n",
       "   Masters 1000  ...  Pl0 Recent Form  Pl0 Form  Pl1 Recent Form  Pl1 Form  \\\n",
       "0             0  ...              0.0       0.0              0.0       0.0   \n",
       "1             0  ...              0.0       0.0              0.0       0.0   \n",
       "2             0  ...              0.0       0.0              0.0       0.0   \n",
       "3             0  ...              0.0       0.0              0.0       0.0   \n",
       "4             0  ...              0.0       0.0              0.0       0.0   \n",
       "\n",
       "   Pl0 Perf. vs Similar Opponent  Pl1 Perf. vs Similar Opponent  \\\n",
       "0                           0.66                           0.17   \n",
       "1                           0.58                           0.24   \n",
       "2                           0.00                           0.91   \n",
       "3                           0.90                           0.30   \n",
       "4                           0.29                           0.36   \n",
       "\n",
       "   Pl0 Surface Performance  Pl1 Surface Performance  H2H Index  Exp Index  \n",
       "0                     0.61                     0.40        0.0        0.0  \n",
       "1                     0.56                     0.51        0.0        0.0  \n",
       "2                     0.14                     0.65        0.0        0.0  \n",
       "3                     0.84                     0.10        0.0        0.0  \n",
       "4                     0.27                     0.46        0.0        0.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    0.0\n",
       "2    1.0\n",
       "3    0.0\n",
       "4    1.0\n",
       "Name: Won, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to split the data into training and testing data.\n",
    "We'll use a 75:25 split, and since we assume each match is independent from the others, we won't shuffle the data randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(inputs, targets, test_size=0.25, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Let's start off with the logistic regression, and see how accurately predicts winners and losers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lreg = LogisticRegression(max_iter=10000, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=2,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lreg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7190418189200163\n"
     ]
    }
   ],
   "source": [
    "score = lreg.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression predicts correctly more than 7 matches out of 10!\n",
    "\n",
    "Since we structured our data to have as many '0' targets than '1' targets, a random model would have approximately 50% accuracy.\n",
    "Jumping from 50% to almost 72% is definetely a good result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "Another popular classifier model is the SVM, Support Vector Machine.\n",
    "Let's see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(kernel = 'rbf')\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.718906482609284\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM model has a 0.718 accuracy, just below the Logistic Regression model!\n",
    "Let's see if we can find better models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier\n",
    "\n",
    "Let's try out the Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.621464338882122\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Decision Tree model, as we can see, is not a very good choice. It returns only a 0.62 prediction accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors\n",
    "\n",
    "Let's see if the KNN model can do a better job than the Logistic Regression and the SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the KNN model we have to pick the right K value, so we're going to fit our model with several values from 1 to 8, and we'll compare the errors of each run.\n",
    "Finally, we'll run the model with the appropriate K value and check its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = []\n",
    "\n",
    "# Calculating error for K values between 1 and 8\n",
    "for i in range(1, 9):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(x_train, y_train)\n",
    "    pred_i = knn.predict(x_test)\n",
    "    error.append(np.mean(pred_i != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Mean Error')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, 9), error, color='red', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='blue', markersize=10)\n",
    "plt.title('Error Rate K Value')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('Mean Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the plot above, we obtain the lowest error with K = 7, so let's use 7 as K parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=7)\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.67      0.67      3688\n",
      "         1.0       0.67      0.67      0.67      3701\n",
      "\n",
      "    accuracy                           0.67      7389\n",
      "   macro avg       0.67      0.67      0.67      7389\n",
      "weighted avg       0.67      0.67      0.67      7389\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN accuracy is around 0.67, so not that great.\n",
    "Let's try Neural Networks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Networks\n",
    "\n",
    "Finally, let's see if we can build a neural network that can achieve a greater accuracy than the Logistic Regression and SVM models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to achieve not only a classification prediction but a probability also, for any given match, the last layer of the neural network will have softmax activation function.\n",
    "However, to use it, we have to build a special \"output\" layer with size 2 and not 1.\n",
    "So let's transform the \"targets\" variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_for_nn = pd.DataFrame()\n",
    "for items in targets.iteritems():\n",
    "    ix = items[0]\n",
    "    winner = items[1]\n",
    "    if winner == 0:\n",
    "        targets_for_nn.at[ix, 'Player 0'] = 1\n",
    "        targets_for_nn.at[ix, 'Player 1'] = 0\n",
    "    else:\n",
    "        targets_for_nn.at[ix, 'Player 0'] = 0\n",
    "        targets_for_nn.at[ix, 'Player 1'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's split again, with targets_for_nn as target\n",
    "x_train, x_test, y_train, y_test = train_test_split(inputs, targets_for_nn, test_size=0.25, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = inputs.shape[1]\n",
    "\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(1000, input_dim=input_cols, activation='relu'))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(60, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dense(7, activation='relu'))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "22165/22165 [==============================] - 4s 177us/step - loss: 0.6314 - accuracy: 0.6655\n",
      "Epoch 2/10\n",
      "22165/22165 [==============================] - 4s 170us/step - loss: 0.5987 - accuracy: 0.6976\n",
      "Epoch 3/10\n",
      "22165/22165 [==============================] - 4s 173us/step - loss: 0.5844 - accuracy: 0.70160s - loss: 0.5860 \n",
      "Epoch 4/10\n",
      "22165/22165 [==============================] - 4s 185us/step - loss: 0.5766 - accuracy: 0.6996\n",
      "Epoch 5/10\n",
      "22165/22165 [==============================] - 4s 191us/step - loss: 0.5713 - accuracy: 0.70330s - loss: 0.5707 - accuracy: 0.\n",
      "Epoch 6/10\n",
      "22165/22165 [==============================] - 4s 175us/step - loss: 0.5656 - accuracy: 0.7043\n",
      "Epoch 7/10\n",
      "22165/22165 [==============================] - 4s 168us/step - loss: 0.5617 - accuracy: 0.7049\n",
      "Epoch 8/10\n",
      "22165/22165 [==============================] - 4s 176us/step - loss: 0.5578 - accuracy: 0.7099\n",
      "Epoch 9/10\n",
      "22165/22165 [==============================] - 4s 171us/step - loss: 0.5565 - accuracy: 0.7051\n",
      "Epoch 10/10\n",
      "22165/22165 [==============================] - 5s 215us/step - loss: 0.5538 - accuracy: 0.7068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x25d35bae8c8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7389/7389 [==============================] - 1s 140us/step\n",
      "Test accuracy: 0.7155230641365051\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we achieved 0.715 accuracy, very similar to the Logistic Regression and SVM models.\n",
    "\n",
    "However, we'll decide to make use of the Logistic Regression model since we can predicts probabilities that each player has to win the match!\n",
    "\n",
    "In this way, we can define the \"predicted\" odds for any given match calculating the logistic regression formula on the inputs features.\n",
    "\n",
    "So let's save our Logistic Regression model, we're going to use it in the next notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'logistic_regression.lr'\n",
    "pickle.dump(lreg, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have saved our model, let's create a coefficients dataframe, so that we associate each input column with the appropriate weight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(inputs.columns)\n",
    "coefs = lreg.coef_.tolist()[0]\n",
    "\n",
    "coef_df_list = []\n",
    "for i in range(0,inputs.shape[1]):\n",
    "    col = cols[i]\n",
    "    coef = coefs[i]\n",
    "    coef_df_list.append({\"Column\":col,\"Coef\":coef})\n",
    "\n",
    "coef_df = pd.DataFrame(coef_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df.to_csv(\"csv/Coefficients.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
