{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Machine Learning Model Building\n",
    "\n",
    "In this notebook, we'll use the dataset elaborated in the previous step to build several machine learning models, including logistic regression, support vector machine, decision tree, k-nearest neighbor and finally a deep learning model.\n",
    "\n",
    "All of these models will try to classify each match into '0' or '1' depending on who's more likely to win each match based on the match features, player 0 or player 1.\n",
    "\n",
    "Finally, we'll compare these models to see which one is more appropriate in our context, and we'll save only one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import pandas library since we're going to work with csv files and dataframe objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the csv file saved in the last notebook, where we added extra-features to help our model make a better prediction job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"csv/FeatureCalculated_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg_Pl1</th>\n",
       "      <th>Avg_Pl0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Pl1_Rank</th>\n",
       "      <th>Player 1</th>\n",
       "      <th>Max_Pl1</th>\n",
       "      <th>Max_Pl0</th>\n",
       "      <th>Pl0_Rank</th>\n",
       "      <th>Player 0</th>\n",
       "      <th>Won</th>\n",
       "      <th>...</th>\n",
       "      <th>The Final</th>\n",
       "      <th>Rank Index</th>\n",
       "      <th>Pl0 Recent Form</th>\n",
       "      <th>Pl0 Form</th>\n",
       "      <th>Pl1 Recent Form</th>\n",
       "      <th>Pl1 Form</th>\n",
       "      <th>Pl0 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl1 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl0 Surface Performance</th>\n",
       "      <th>Pl1 Surface Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>63</td>\n",
       "      <td>Dosedel S.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77</td>\n",
       "      <td>Ljubicic I.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>56</td>\n",
       "      <td>Clement A.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Enqvist T.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>40</td>\n",
       "      <td>Escude N.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>655</td>\n",
       "      <td>Baccanello P.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.8309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>87</td>\n",
       "      <td>Knippschild J.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>Federer R.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>81</td>\n",
       "      <td>Fromberg R.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>198</td>\n",
       "      <td>Woodbridge T.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.2478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Avg_Pl1  Avg_Pl0        Date  Pl1_Rank        Player 1  Max_Pl1  Max_Pl0  \\\n",
       "0      NaN      NaN  2000-01-03        63      Dosedel S.      NaN      NaN   \n",
       "1      NaN      NaN  2000-01-03        56      Clement A.      NaN      NaN   \n",
       "2      NaN      NaN  2000-01-03        40       Escude N.      NaN      NaN   \n",
       "3      NaN      NaN  2000-01-03        87  Knippschild J.      NaN      NaN   \n",
       "4      NaN      NaN  2000-01-03        81     Fromberg R.      NaN      NaN   \n",
       "\n",
       "   Pl0_Rank       Player 0  Won  ...  The Final  Rank Index  Pl0 Recent Form  \\\n",
       "0        77    Ljubicic I.  1.0  ...          0     -0.0182              0.0   \n",
       "1         5     Enqvist T.  0.0  ...          0      0.7614              0.0   \n",
       "2       655  Baccanello P.  1.0  ...          0     -0.8309              0.0   \n",
       "3        65     Federer R.  0.0  ...          0      0.0366              0.0   \n",
       "4       198  Woodbridge T.  1.0  ...          0     -0.2478              0.0   \n",
       "\n",
       "   Pl0 Form  Pl1 Recent Form  Pl1 Form  Pl0 Perf. vs Similar Opponent  \\\n",
       "0       0.0              0.0       0.0                           0.66   \n",
       "1       0.0              0.0       0.0                           0.58   \n",
       "2       0.0              0.0       0.0                           0.00   \n",
       "3       0.0              0.0       0.0                           0.90   \n",
       "4       0.0              0.0       0.0                           0.29   \n",
       "\n",
       "   Pl1 Perf. vs Similar Opponent  Pl0 Surface Performance  \\\n",
       "0                           0.17                     0.61   \n",
       "1                           0.24                     0.56   \n",
       "2                           0.91                     0.14   \n",
       "3                           0.30                     0.84   \n",
       "4                           0.36                     0.27   \n",
       "\n",
       "   Pl1 Surface Performance  \n",
       "0                     0.40  \n",
       "1                     0.51  \n",
       "2                     0.65  \n",
       "3                     0.10  \n",
       "4                     0.46  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before picking up our models, we have to extract the inputs and the targets from this dataset.\n",
    "The target variable is only one, the \"Won\" column.\n",
    "The inputs variables start with the dummy categories we introduced in the preprocessing stage until the last columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Avg_Pl1',\n",
       " 'Avg_Pl0',\n",
       " 'Date',\n",
       " 'Pl1_Rank',\n",
       " 'Player 1',\n",
       " 'Max_Pl1',\n",
       " 'Max_Pl0',\n",
       " 'Pl0_Rank',\n",
       " 'Player 0',\n",
       " 'Won',\n",
       " 'Indoor',\n",
       " 'Outdoor',\n",
       " 'Carpet',\n",
       " 'Clay',\n",
       " 'Grass',\n",
       " 'Hard',\n",
       " 'ATP250',\n",
       " 'ATP500',\n",
       " 'Grand Slam',\n",
       " 'Masters 1000',\n",
       " 'Masters Cup',\n",
       " '1st Round',\n",
       " '2nd Round',\n",
       " '3rd Round',\n",
       " '4th Round',\n",
       " 'Quarterfinals',\n",
       " 'Round Robin',\n",
       " 'Semifinals',\n",
       " 'The Final',\n",
       " 'Rank Index',\n",
       " 'Pl0 Recent Form',\n",
       " 'Pl0 Form',\n",
       " 'Pl1 Recent Form',\n",
       " 'Pl1 Form',\n",
       " 'Pl0 Perf. vs Similar Opponent',\n",
       " 'Pl1 Perf. vs Similar Opponent',\n",
       " 'Pl0 Surface Performance',\n",
       " 'Pl1 Surface Performance']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before splitting our dataset in inputs and targets, we specify a subset of the dataframe containing only matches that are not going to be used in the \"Betting simulation\" stage, so for modeling we're going to pick only matches that don't have information about average and max odds for the players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg_Pl1</th>\n",
       "      <th>Avg_Pl0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Pl1_Rank</th>\n",
       "      <th>Player 1</th>\n",
       "      <th>Max_Pl1</th>\n",
       "      <th>Max_Pl0</th>\n",
       "      <th>Pl0_Rank</th>\n",
       "      <th>Player 0</th>\n",
       "      <th>Won</th>\n",
       "      <th>...</th>\n",
       "      <th>The Final</th>\n",
       "      <th>Rank Index</th>\n",
       "      <th>Pl0 Recent Form</th>\n",
       "      <th>Pl0 Form</th>\n",
       "      <th>Pl1 Recent Form</th>\n",
       "      <th>Pl1 Form</th>\n",
       "      <th>Pl0 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl1 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl0 Surface Performance</th>\n",
       "      <th>Pl1 Surface Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>63</td>\n",
       "      <td>Dosedel S.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77</td>\n",
       "      <td>Ljubicic I.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>56</td>\n",
       "      <td>Clement A.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Enqvist T.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>40</td>\n",
       "      <td>Escude N.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>655</td>\n",
       "      <td>Baccanello P.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.8309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>87</td>\n",
       "      <td>Knippschild J.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>Federer R.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>81</td>\n",
       "      <td>Fromberg R.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>198</td>\n",
       "      <td>Woodbridge T.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.2478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Avg_Pl1  Avg_Pl0        Date  Pl1_Rank        Player 1  Max_Pl1  Max_Pl0  \\\n",
       "0      NaN      NaN  2000-01-03        63      Dosedel S.      NaN      NaN   \n",
       "1      NaN      NaN  2000-01-03        56      Clement A.      NaN      NaN   \n",
       "2      NaN      NaN  2000-01-03        40       Escude N.      NaN      NaN   \n",
       "3      NaN      NaN  2000-01-03        87  Knippschild J.      NaN      NaN   \n",
       "4      NaN      NaN  2000-01-03        81     Fromberg R.      NaN      NaN   \n",
       "\n",
       "   Pl0_Rank       Player 0  Won  ...  The Final  Rank Index  Pl0 Recent Form  \\\n",
       "0        77    Ljubicic I.  1.0  ...          0     -0.0182              0.0   \n",
       "1         5     Enqvist T.  0.0  ...          0      0.7614              0.0   \n",
       "2       655  Baccanello P.  1.0  ...          0     -0.8309              0.0   \n",
       "3        65     Federer R.  0.0  ...          0      0.0366              0.0   \n",
       "4       198  Woodbridge T.  1.0  ...          0     -0.2478              0.0   \n",
       "\n",
       "   Pl0 Form  Pl1 Recent Form  Pl1 Form  Pl0 Perf. vs Similar Opponent  \\\n",
       "0       0.0              0.0       0.0                           0.66   \n",
       "1       0.0              0.0       0.0                           0.58   \n",
       "2       0.0              0.0       0.0                           0.00   \n",
       "3       0.0              0.0       0.0                           0.90   \n",
       "4       0.0              0.0       0.0                           0.29   \n",
       "\n",
       "   Pl1 Perf. vs Similar Opponent  Pl0 Surface Performance  \\\n",
       "0                           0.17                     0.61   \n",
       "1                           0.24                     0.56   \n",
       "2                           0.91                     0.14   \n",
       "3                           0.30                     0.84   \n",
       "4                           0.36                     0.27   \n",
       "\n",
       "   Pl1 Surface Performance  \n",
       "0                     0.40  \n",
       "1                     0.51  \n",
       "2                     0.65  \n",
       "3                     0.10  \n",
       "4                     0.46  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nobets_df = df[(df[\"Avg_Pl0\"].isnull()) | (df[\"Avg_Pl1\"].isnull()) | (df[\"Max_Pl0\"].isnull()) | (df[\"Max_Pl1\"].isnull())]\n",
    "nobets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = nobets_df.iloc[:, 10:]\n",
    "targets = nobets_df.iloc[:, 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at \"inputs\" and \"targets\" content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Indoor</th>\n",
       "      <th>Outdoor</th>\n",
       "      <th>Carpet</th>\n",
       "      <th>Clay</th>\n",
       "      <th>Grass</th>\n",
       "      <th>Hard</th>\n",
       "      <th>ATP250</th>\n",
       "      <th>ATP500</th>\n",
       "      <th>Grand Slam</th>\n",
       "      <th>Masters 1000</th>\n",
       "      <th>...</th>\n",
       "      <th>The Final</th>\n",
       "      <th>Rank Index</th>\n",
       "      <th>Pl0 Recent Form</th>\n",
       "      <th>Pl0 Form</th>\n",
       "      <th>Pl1 Recent Form</th>\n",
       "      <th>Pl1 Form</th>\n",
       "      <th>Pl0 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl1 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl0 Surface Performance</th>\n",
       "      <th>Pl1 Surface Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.8309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.2478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Indoor  Outdoor  Carpet  Clay  Grass  Hard  ATP250  ATP500  Grand Slam  \\\n",
       "0       0        1       0     0      0     1       1       0           0   \n",
       "1       0        1       0     0      0     1       1       0           0   \n",
       "2       0        1       0     0      0     1       1       0           0   \n",
       "3       0        1       0     0      0     1       1       0           0   \n",
       "4       0        1       0     0      0     1       1       0           0   \n",
       "\n",
       "   Masters 1000  ...  The Final  Rank Index  Pl0 Recent Form  Pl0 Form  \\\n",
       "0             0  ...          0     -0.0182              0.0       0.0   \n",
       "1             0  ...          0      0.7614              0.0       0.0   \n",
       "2             0  ...          0     -0.8309              0.0       0.0   \n",
       "3             0  ...          0      0.0366              0.0       0.0   \n",
       "4             0  ...          0     -0.2478              0.0       0.0   \n",
       "\n",
       "   Pl1 Recent Form  Pl1 Form  Pl0 Perf. vs Similar Opponent  \\\n",
       "0              0.0       0.0                           0.66   \n",
       "1              0.0       0.0                           0.58   \n",
       "2              0.0       0.0                           0.00   \n",
       "3              0.0       0.0                           0.90   \n",
       "4              0.0       0.0                           0.29   \n",
       "\n",
       "   Pl1 Perf. vs Similar Opponent  Pl0 Surface Performance  \\\n",
       "0                           0.17                     0.61   \n",
       "1                           0.24                     0.56   \n",
       "2                           0.91                     0.14   \n",
       "3                           0.30                     0.84   \n",
       "4                           0.36                     0.27   \n",
       "\n",
       "   Pl1 Surface Performance  \n",
       "0                     0.40  \n",
       "1                     0.51  \n",
       "2                     0.65  \n",
       "3                     0.10  \n",
       "4                     0.46  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    0.0\n",
       "2    1.0\n",
       "3    0.0\n",
       "4    1.0\n",
       "Name: Won, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to split the data into training and testing data.\n",
    "We'll use a 75:25 split, and since we assume each match is independent from the others, we won't shuffle the data randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(inputs, targets, test_size=0.25, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Let's start off with the logistic regression, and see how accurately predicts winners and losers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lreg = LogisticRegression(max_iter=10000, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=2,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lreg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7193124915414806\n"
     ]
    }
   ],
   "source": [
    "score = lreg.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression predicts correctly more than 7 matches out of 10!\n",
    "\n",
    "Since we structured our data to have as many '0' targets than '1' targets, a random model would have approximately 50% accuracy.\n",
    "Jumping from 50% to almost 72% is definetely a good result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "Another popular classifier model is the SVM, Support Vector Machine.\n",
    "Let's see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(kernel = 'rbf')\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.717282446880498\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM model has a 0.717 accuracy, just below the Logistic Regression model!\n",
    "Let's see if we can find better models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier\n",
    "\n",
    "Let's try out the Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6351333062660712\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Decision Tree model, as we can see, is not a very good choice. It returns only a 0.63 prediction accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors\n",
    "\n",
    "Let's see if the KNN model can do a better job than the Logistic Regression and the SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the KNN model we have to pick the right K value, so we're going to fit our model with several values from 1 to 8, and we'll compare the errors of each run.\n",
    "Finally, we'll run the model with the appropriate K value and check its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = []\n",
    "\n",
    "# Calculating error for K values between 1 and 8\n",
    "for i in range(1, 9):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(x_train, y_train)\n",
    "    pred_i = knn.predict(x_test)\n",
    "    error.append(np.mean(pred_i != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Mean Error')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, 9), error, color='red', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='blue', markersize=10)\n",
    "plt.title('Error Rate K Value')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('Mean Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the plot above, we obtain the lowest error with K = 7, so let's use 7 as K parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=7)\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.67      0.67      3688\n",
      "         1.0       0.68      0.68      0.68      3701\n",
      "\n",
      "    accuracy                           0.67      7389\n",
      "   macro avg       0.67      0.67      0.67      7389\n",
      "weighted avg       0.67      0.67      0.67      7389\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN accuracy is around 0.67, so not that great.\n",
    "Let's try Neural Networks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Networks\n",
    "\n",
    "Finally, let's see if we can build a neural network that can achieve a greater accuracy than the Logistic Regression and SVM models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to achieve not only a classification prediction but a probability also, for any given match, the last layer of the neural network will have softmax activation function.\n",
    "However, to use it, we have to build a special \"output\" layer with size 2 and not 1.\n",
    "So let's transform the \"targets\" variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_for_nn = pd.DataFrame()\n",
    "for items in targets.iteritems():\n",
    "    ix = items[0]\n",
    "    winner = items[1]\n",
    "    if winner == 0:\n",
    "        targets_for_nn.at[ix, 'Player 0'] = 1\n",
    "        targets_for_nn.at[ix, 'Player 1'] = 0\n",
    "    else:\n",
    "        targets_for_nn.at[ix, 'Player 0'] = 0\n",
    "        targets_for_nn.at[ix, 'Player 1'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's split again, with targets_for_nn as target\n",
    "x_train, x_test, y_train, y_test = train_test_split(inputs, targets_for_nn, test_size=0.25, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = inputs.shape[1]\n",
    "\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(1000, input_dim=input_cols, activation='relu'))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(60, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dense(7, activation='relu'))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "22165/22165 [==============================] - 4s 185us/step - loss: 0.6329 - accuracy: 0.6617\n",
      "Epoch 2/10\n",
      "22165/22165 [==============================] - 4s 179us/step - loss: 0.6003 - accuracy: 0.6973\n",
      "Epoch 3/10\n",
      "22165/22165 [==============================] - 4s 170us/step - loss: 0.5873 - accuracy: 0.6983\n",
      "Epoch 4/10\n",
      "22165/22165 [==============================] - 5s 204us/step - loss: 0.5815 - accuracy: 0.70033s - loss: 0.5908  - ETA: 2s - loss: 0 - ETA: \n",
      "Epoch 5/10\n",
      "22165/22165 [==============================] - 5s 207us/step - loss: 0.5715 - accuracy: 0.7040\n",
      "Epoch 6/10\n",
      "22165/22165 [==============================] - 5s 206us/step - loss: 0.5671 - accuracy: 0.7043\n",
      "Epoch 7/10\n",
      "22165/22165 [==============================] - 4s 202us/step - loss: 0.5658 - accuracy: 0.70221s -\n",
      "Epoch 8/10\n",
      "22165/22165 [==============================] - 4s 174us/step - loss: 0.5609 - accuracy: 0.7074\n",
      "Epoch 9/10\n",
      "22165/22165 [==============================] - 4s 184us/step - loss: 0.5614 - accuracy: 0.70441s - loss: - ETA: 0s - loss: 0.5\n",
      "Epoch 10/10\n",
      "22165/22165 [==============================] - 4s 186us/step - loss: 0.5559 - accuracy: 0.7062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1d82f4a7708>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7389/7389 [==============================] - 1s 94us/step\n",
      "Test accuracy: 0.71471107006073\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we achieved 0.717 accuracy, very similar to the Logistic Regression and SVM models.\n",
    "\n",
    "However, we'll decide to make use of the Logistic Regression model since we can predicts probabilities that each player has to win the match!\n",
    "\n",
    "In this way, we can define the \"predicted\" odds for any given match calculating the logistic regression formula on the inputs features.\n",
    "\n",
    "So let's save our Logistic Regression model, we're going to use it in the next notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'logistic_regression.lr'\n",
    "pickle.dump(lreg, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have saved our model, let's create a coefficients dataframe, so that we associate each input column with the appropriate weight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(inputs.columns)\n",
    "coefs = lreg.coef_.tolist()[0]\n",
    "\n",
    "coef_df_list = []\n",
    "for i in range(0,inputs.shape[1]):\n",
    "    col = cols[i]\n",
    "    coef = coefs[i]\n",
    "    coef_df_list.append({\"Column\":col,\"Coef\":coef})\n",
    "\n",
    "coef_df = pd.DataFrame(coef_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df.to_csv(\"csv/Coefficients.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
