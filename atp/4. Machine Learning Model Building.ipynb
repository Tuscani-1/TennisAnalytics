{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Machine Learning Model Building\n",
    "\n",
    "In this notebook, we'll use the dataset elaborated in the previous step to build several machine learning models, including logistic regression, support vector machine, decision tree, k-nearest neighbor and finally a deep learning model.\n",
    "\n",
    "All of these models will try to classify each match into '0' or '1' depending on who's more likely to win each match based on the match features, player 0 or player 1.\n",
    "\n",
    "Finally, we'll compare these models to see which one is more appropriate in our context, and we'll save only one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import pandas library since we're going to work with csv files and dataframe objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the csv file saved in the last notebook, where we added extra-features to help our model make a better prediction job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"csv/FeatureCalculated_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Player 0</th>\n",
       "      <th>Player 1</th>\n",
       "      <th>Won</th>\n",
       "      <th>Pl0_Rank</th>\n",
       "      <th>Pl1_Rank</th>\n",
       "      <th>Avg_Pl0</th>\n",
       "      <th>Avg_Pl1</th>\n",
       "      <th>Max_Pl1</th>\n",
       "      <th>Max_Pl0</th>\n",
       "      <th>...</th>\n",
       "      <th>Pl1 Recent Form</th>\n",
       "      <th>Pl1 Form</th>\n",
       "      <th>Pl0 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl1 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl0 Surface Performance</th>\n",
       "      <th>Pl1 Surface Performance</th>\n",
       "      <th>H2H Index</th>\n",
       "      <th>Exp Index</th>\n",
       "      <th>Reliability Pl0</th>\n",
       "      <th>Reliability Pl1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>Ljubicic I.</td>\n",
       "      <td>Dosedel S.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.687008</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>Enqvist T.</td>\n",
       "      <td>Clement A.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.640805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>Baccanello P.</td>\n",
       "      <td>Escude N.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>655</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.680851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>Federer R.</td>\n",
       "      <td>Knippschild J.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.868249</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>Woodbridge T.</td>\n",
       "      <td>Fromberg R.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>198</td>\n",
       "      <td>81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Player 0        Player 1  Won  Pl0_Rank  Pl1_Rank  \\\n",
       "0  2000-01-03    Ljubicic I.      Dosedel S.  1.0        77        63   \n",
       "1  2000-01-03     Enqvist T.      Clement A.  0.0         5        56   \n",
       "2  2000-01-03  Baccanello P.       Escude N.  1.0       655        40   \n",
       "3  2000-01-03     Federer R.  Knippschild J.  0.0        65        87   \n",
       "4  2000-01-03  Woodbridge T.     Fromberg R.  1.0       198        81   \n",
       "\n",
       "   Avg_Pl0  Avg_Pl1  Max_Pl1  Max_Pl0  ...  Pl1 Recent Form  Pl1 Form  \\\n",
       "0      NaN      NaN      NaN      NaN  ...              0.0       0.0   \n",
       "1      NaN      NaN      NaN      NaN  ...              0.0       0.0   \n",
       "2      NaN      NaN      NaN      NaN  ...              0.0       0.0   \n",
       "3      NaN      NaN      NaN      NaN  ...              0.0       0.0   \n",
       "4      NaN      NaN      NaN      NaN  ...              0.0       0.0   \n",
       "\n",
       "   Pl0 Perf. vs Similar Opponent  Pl1 Perf. vs Similar Opponent  \\\n",
       "0                           0.66                           0.17   \n",
       "1                           0.58                           0.24   \n",
       "2                           0.00                           0.91   \n",
       "3                           0.90                           0.30   \n",
       "4                           0.29                           0.36   \n",
       "\n",
       "   Pl0 Surface Performance  Pl1 Surface Performance  H2H Index  Exp Index  \\\n",
       "0                     0.61                     0.40        0.0        0.0   \n",
       "1                     0.56                     0.51        0.0        0.0   \n",
       "2                     0.14                     0.65        0.0        0.0   \n",
       "3                     0.84                     0.10        0.0        0.0   \n",
       "4                     0.27                     0.46        0.0        0.0   \n",
       "\n",
       "   Reliability Pl0  Reliability Pl1  \n",
       "0         0.687008         0.000000  \n",
       "1         0.625000         0.640805  \n",
       "2         0.750000         0.680851  \n",
       "3         0.868249         1.000000  \n",
       "4         0.000000         0.000000  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before picking up our models, we have to extract the inputs and the targets from this dataset.\n",
    "The target variable is only one, the \"Won\" column.\n",
    "The inputs variables start with the dummy categories we introduced in the preprocessing stage until the last columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date',\n",
       " 'Player 0',\n",
       " 'Player 1',\n",
       " 'Won',\n",
       " 'Pl0_Rank',\n",
       " 'Pl1_Rank',\n",
       " 'Avg_Pl0',\n",
       " 'Avg_Pl1',\n",
       " 'Max_Pl1',\n",
       " 'Max_Pl0',\n",
       " 'PS_Pl0',\n",
       " 'PS_Pl1',\n",
       " 'B365_Pl0',\n",
       " 'B365_Pl1',\n",
       " 'Indoor',\n",
       " 'Outdoor',\n",
       " 'Carpet',\n",
       " 'Clay',\n",
       " 'Grass',\n",
       " 'Hard',\n",
       " 'ATP250',\n",
       " 'ATP500',\n",
       " 'Grand Slam',\n",
       " 'Masters 1000',\n",
       " 'Masters Cup',\n",
       " '1st Round',\n",
       " '2nd Round',\n",
       " '3rd Round',\n",
       " '4th Round',\n",
       " 'Quarterfinals',\n",
       " 'Round Robin',\n",
       " 'Semifinals',\n",
       " 'The Final',\n",
       " 'Rank Index',\n",
       " 'Pl0 Recent Form',\n",
       " 'Pl0 Form',\n",
       " 'Pl1 Recent Form',\n",
       " 'Pl1 Form',\n",
       " 'Pl0 Perf. vs Similar Opponent',\n",
       " 'Pl1 Perf. vs Similar Opponent',\n",
       " 'Pl0 Surface Performance',\n",
       " 'Pl1 Surface Performance',\n",
       " 'H2H Index',\n",
       " 'Exp Index',\n",
       " 'Reliability Pl0',\n",
       " 'Reliability Pl1']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before splitting our dataset in inputs and targets, we specify a subset of the dataframe containing only matches that are not going to be used in the \"Betting simulation\" stage, so for modeling we're going to pick only matches that don't have information about average and max odds for the players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Player 0</th>\n",
       "      <th>Player 1</th>\n",
       "      <th>Won</th>\n",
       "      <th>Pl0_Rank</th>\n",
       "      <th>Pl1_Rank</th>\n",
       "      <th>Avg_Pl0</th>\n",
       "      <th>Avg_Pl1</th>\n",
       "      <th>Max_Pl1</th>\n",
       "      <th>Max_Pl0</th>\n",
       "      <th>...</th>\n",
       "      <th>Pl1 Recent Form</th>\n",
       "      <th>Pl1 Form</th>\n",
       "      <th>Pl0 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl1 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl0 Surface Performance</th>\n",
       "      <th>Pl1 Surface Performance</th>\n",
       "      <th>H2H Index</th>\n",
       "      <th>Exp Index</th>\n",
       "      <th>Reliability Pl0</th>\n",
       "      <th>Reliability Pl1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>Ljubicic I.</td>\n",
       "      <td>Dosedel S.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.687008</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>Enqvist T.</td>\n",
       "      <td>Clement A.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.640805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>Baccanello P.</td>\n",
       "      <td>Escude N.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>655</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.680851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>Federer R.</td>\n",
       "      <td>Knippschild J.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.868249</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>Woodbridge T.</td>\n",
       "      <td>Fromberg R.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>198</td>\n",
       "      <td>81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Player 0        Player 1  Won  Pl0_Rank  Pl1_Rank  \\\n",
       "0  2000-01-03    Ljubicic I.      Dosedel S.  1.0        77        63   \n",
       "1  2000-01-03     Enqvist T.      Clement A.  0.0         5        56   \n",
       "2  2000-01-03  Baccanello P.       Escude N.  1.0       655        40   \n",
       "3  2000-01-03     Federer R.  Knippschild J.  0.0        65        87   \n",
       "4  2000-01-03  Woodbridge T.     Fromberg R.  1.0       198        81   \n",
       "\n",
       "   Avg_Pl0  Avg_Pl1  Max_Pl1  Max_Pl0  ...  Pl1 Recent Form  Pl1 Form  \\\n",
       "0      NaN      NaN      NaN      NaN  ...              0.0       0.0   \n",
       "1      NaN      NaN      NaN      NaN  ...              0.0       0.0   \n",
       "2      NaN      NaN      NaN      NaN  ...              0.0       0.0   \n",
       "3      NaN      NaN      NaN      NaN  ...              0.0       0.0   \n",
       "4      NaN      NaN      NaN      NaN  ...              0.0       0.0   \n",
       "\n",
       "   Pl0 Perf. vs Similar Opponent  Pl1 Perf. vs Similar Opponent  \\\n",
       "0                           0.66                           0.17   \n",
       "1                           0.58                           0.24   \n",
       "2                           0.00                           0.91   \n",
       "3                           0.90                           0.30   \n",
       "4                           0.29                           0.36   \n",
       "\n",
       "   Pl0 Surface Performance  Pl1 Surface Performance  H2H Index  Exp Index  \\\n",
       "0                     0.61                     0.40        0.0        0.0   \n",
       "1                     0.56                     0.51        0.0        0.0   \n",
       "2                     0.14                     0.65        0.0        0.0   \n",
       "3                     0.84                     0.10        0.0        0.0   \n",
       "4                     0.27                     0.46        0.0        0.0   \n",
       "\n",
       "   Reliability Pl0  Reliability Pl1  \n",
       "0         0.687008         0.000000  \n",
       "1         0.625000         0.640805  \n",
       "2         0.750000         0.680851  \n",
       "3         0.868249         1.000000  \n",
       "4         0.000000         0.000000  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nobets_df = df[(df[\"Avg_Pl0\"].isnull()) | (df[\"Avg_Pl1\"].isnull()) | (df[\"Max_Pl0\"].isnull()) | (df[\"Max_Pl1\"].isnull())]\n",
    "nobets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = nobets_df.iloc[:, 14:]\n",
    "targets = nobets_df.iloc[:, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at \"inputs\" and \"targets\" content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Indoor</th>\n",
       "      <th>Outdoor</th>\n",
       "      <th>Carpet</th>\n",
       "      <th>Clay</th>\n",
       "      <th>Grass</th>\n",
       "      <th>Hard</th>\n",
       "      <th>ATP250</th>\n",
       "      <th>ATP500</th>\n",
       "      <th>Grand Slam</th>\n",
       "      <th>Masters 1000</th>\n",
       "      <th>...</th>\n",
       "      <th>Pl1 Recent Form</th>\n",
       "      <th>Pl1 Form</th>\n",
       "      <th>Pl0 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl1 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl0 Surface Performance</th>\n",
       "      <th>Pl1 Surface Performance</th>\n",
       "      <th>H2H Index</th>\n",
       "      <th>Exp Index</th>\n",
       "      <th>Reliability Pl0</th>\n",
       "      <th>Reliability Pl1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.687008</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.640805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.680851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.868249</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Indoor  Outdoor  Carpet  Clay  Grass  Hard  ATP250  ATP500  Grand Slam  \\\n",
       "0       0        1       0     0      0     1       1       0           0   \n",
       "1       0        1       0     0      0     1       1       0           0   \n",
       "2       0        1       0     0      0     1       1       0           0   \n",
       "3       0        1       0     0      0     1       1       0           0   \n",
       "4       0        1       0     0      0     1       1       0           0   \n",
       "\n",
       "   Masters 1000  ...  Pl1 Recent Form  Pl1 Form  \\\n",
       "0             0  ...              0.0       0.0   \n",
       "1             0  ...              0.0       0.0   \n",
       "2             0  ...              0.0       0.0   \n",
       "3             0  ...              0.0       0.0   \n",
       "4             0  ...              0.0       0.0   \n",
       "\n",
       "   Pl0 Perf. vs Similar Opponent  Pl1 Perf. vs Similar Opponent  \\\n",
       "0                           0.66                           0.17   \n",
       "1                           0.58                           0.24   \n",
       "2                           0.00                           0.91   \n",
       "3                           0.90                           0.30   \n",
       "4                           0.29                           0.36   \n",
       "\n",
       "   Pl0 Surface Performance  Pl1 Surface Performance  H2H Index  Exp Index  \\\n",
       "0                     0.61                     0.40        0.0        0.0   \n",
       "1                     0.56                     0.51        0.0        0.0   \n",
       "2                     0.14                     0.65        0.0        0.0   \n",
       "3                     0.84                     0.10        0.0        0.0   \n",
       "4                     0.27                     0.46        0.0        0.0   \n",
       "\n",
       "   Reliability Pl0  Reliability Pl1  \n",
       "0         0.687008         0.000000  \n",
       "1         0.625000         0.640805  \n",
       "2         0.750000         0.680851  \n",
       "3         0.868249         1.000000  \n",
       "4         0.000000         0.000000  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    0.0\n",
       "2    1.0\n",
       "3    0.0\n",
       "4    1.0\n",
       "Name: Won, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to split the data into training and testing data.\n",
    "We'll use a 75:25 split, and since we assume each match is independent from the others, we won't shuffle the data randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(inputs, targets, test_size=0.25, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Let's start off with the logistic regression, and see how accurately predicts winners and losers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lreg = LogisticRegression(max_iter=10000, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=2,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lreg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7193124915414806\n"
     ]
    }
   ],
   "source": [
    "score = lreg.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression predicts correctly more than 7 matches out of 10!\n",
    "\n",
    "Since we structured our data to have as many '0' targets than '1' targets, a random model would have approximately 50% accuracy.\n",
    "Jumping from 50% to almost 72% is definetely a good result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "Another popular classifier model is the SVM, Support Vector Machine.\n",
    "Let's see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(kernel = 'rbf')\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.718906482609284\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM model has a 0.718 accuracy, just below the Logistic Regression model!\n",
    "Let's see if we can find better models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier\n",
    "\n",
    "Let's try out the Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6289078359723914\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Decision Tree model, as we can see, is not a very good choice. It returns only a 0.62 prediction accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors\n",
    "\n",
    "Let's see if the KNN model can do a better job than the Logistic Regression and the SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the KNN model we have to pick the right K value, so we're going to fit our model with several values from 1 to 8, and we'll compare the errors of each run.\n",
    "Finally, we'll run the model with the appropriate K value and check its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = []\n",
    "\n",
    "# Calculating error for K values between 1 and 8\n",
    "for i in range(1, 9):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(x_train, y_train)\n",
    "    pred_i = knn.predict(x_test)\n",
    "    error.append(np.mean(pred_i != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Mean Error')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, 9), error, color='red', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='blue', markersize=10)\n",
    "plt.title('Error Rate K Value')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('Mean Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the plot above, we obtain the lowest error with K = 7, so let's use 7 as K parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=7)\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.66      0.66      3688\n",
      "         1.0       0.66      0.67      0.67      3701\n",
      "\n",
      "    accuracy                           0.66      7389\n",
      "   macro avg       0.66      0.66      0.66      7389\n",
      "weighted avg       0.66      0.66      0.66      7389\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN accuracy is around 0.66, so not that great.\n",
    "Let's try Neural Networks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Networks\n",
    "\n",
    "Finally, let's see if we can build a neural network that can achieve a greater accuracy than the Logistic Regression and SVM models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to achieve not only a classification prediction but a probability also, for any given match, the last layer of the neural network will have softmax activation function.\n",
    "However, to use it, we have to build a special \"output\" layer with size 2 and not 1.\n",
    "So let's transform the \"targets\" variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_for_nn = pd.DataFrame()\n",
    "for items in targets.iteritems():\n",
    "    ix = items[0]\n",
    "    winner = items[1]\n",
    "    if winner == 0:\n",
    "        targets_for_nn.at[ix, 'Player 0'] = 1\n",
    "        targets_for_nn.at[ix, 'Player 1'] = 0\n",
    "    else:\n",
    "        targets_for_nn.at[ix, 'Player 0'] = 0\n",
    "        targets_for_nn.at[ix, 'Player 1'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's split again, with targets_for_nn as target\n",
    "x_train, x_test, y_train, y_test = train_test_split(inputs, targets_for_nn, test_size=0.25, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = inputs.shape[1]\n",
    "\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(1000, input_dim=input_cols, activation='relu'))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(60, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dense(7, activation='relu'))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "22165/22165 [==============================] - 3s 153us/step - loss: 0.6037 - accuracy: 0.6688\n",
      "Epoch 2/10\n",
      "22165/22165 [==============================] - 3s 146us/step - loss: 0.5609 - accuracy: 0.6977\n",
      "Epoch 3/10\n",
      "22165/22165 [==============================] - 4s 163us/step - loss: 0.5538 - accuracy: 0.7050\n",
      "Epoch 4/10\n",
      "22165/22165 [==============================] - 4s 162us/step - loss: 0.5516 - accuracy: 0.7046\n",
      "Epoch 5/10\n",
      "22165/22165 [==============================] - 4s 180us/step - loss: 0.5494 - accuracy: 0.7050\n",
      "Epoch 6/10\n",
      "22165/22165 [==============================] - 3s 150us/step - loss: 0.5462 - accuracy: 0.7038\n",
      "Epoch 7/10\n",
      "22165/22165 [==============================] - 4s 160us/step - loss: 0.5435 - accuracy: 0.7073\n",
      "Epoch 8/10\n",
      "22165/22165 [==============================] - 3s 139us/step - loss: 0.5399 - accuracy: 0.7067\n",
      "Epoch 9/10\n",
      "22165/22165 [==============================] - 3s 147us/step - loss: 0.5398 - accuracy: 0.7075\n",
      "Epoch 10/10\n",
      "22165/22165 [==============================] - 3s 139us/step - loss: 0.5382 - accuracy: 0.7093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1de43746288>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7389/7389 [==============================] - 1s 95us/step\n",
      "Test accuracy: 0.7092975974082947\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we achieved 0.709 accuracy, very similar to the Logistic Regression and SVM models.\n",
    "\n",
    "However, we'll decide to make use of the Logistic Regression model since we can predicts probabilities that each player has to win the match!\n",
    "\n",
    "In this way, we can define the \"predicted\" odds for any given match calculating the logistic regression formula on the inputs features.\n",
    "\n",
    "So let's save our Logistic Regression model, we're going to use it in the next notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'logistic_regression.lr'\n",
    "pickle.dump(lreg, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have saved our model, let's create a coefficients dataframe, so that we associate each input column with the appropriate weight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(inputs.columns)\n",
    "coefs = lreg.coef_.tolist()[0]\n",
    "\n",
    "coef_df_list = []\n",
    "for i in range(0,inputs.shape[1]):\n",
    "    col = cols[i]\n",
    "    coef = coefs[i]\n",
    "    coef_df_list.append({\"Column\":col,\"Coef\":coef})\n",
    "\n",
    "coef_df = pd.DataFrame(coef_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df.to_csv(\"csv/Coefficients.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
