{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Machine Learning Model Building\n",
    "\n",
    "In this notebook, we'll use the dataset elaborated in the previous step to build several machine learning models, including logistic regression, support vector machine, decision tree, k-nearest neighbor and finally a deep learning model.\n",
    "\n",
    "All of these models will try to classify each match into '0' or '1' depending on who's more likely to win each match based on the match features, player 0 or player 1.\n",
    "\n",
    "Finally, we'll compare these models to see which one is more appropriate in our context, and we'll save only one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import pandas library since we're going to work with csv files and dataframe objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the csv file saved in the last notebook, where we added extra-features to help our model make a better prediction job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"csv/FeatureCalculated_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Player 0</th>\n",
       "      <th>Player 1</th>\n",
       "      <th>Won</th>\n",
       "      <th>Pl0_Rank</th>\n",
       "      <th>Pl1_Rank</th>\n",
       "      <th>Avg_Pl0</th>\n",
       "      <th>Avg_Pl1</th>\n",
       "      <th>Max_Pl1</th>\n",
       "      <th>Max_Pl0</th>\n",
       "      <th>...</th>\n",
       "      <th>Pl1 Recent Form</th>\n",
       "      <th>Pl1 Form</th>\n",
       "      <th>Pl0 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl1 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl0 Surface Performance</th>\n",
       "      <th>Pl1 Surface Performance</th>\n",
       "      <th>H2H Index</th>\n",
       "      <th>Exp Index</th>\n",
       "      <th>Reliability Pl0</th>\n",
       "      <th>Reliability Pl1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>Ljubicic I.</td>\n",
       "      <td>Dosedel S.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.687008</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>Enqvist T.</td>\n",
       "      <td>Clement A.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.640805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>Baccanello P.</td>\n",
       "      <td>Escude N.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>655</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.680851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>Federer R.</td>\n",
       "      <td>Knippschild J.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.868249</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>Woodbridge T.</td>\n",
       "      <td>Fromberg R.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>198</td>\n",
       "      <td>81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Player 0        Player 1  Won  Pl0_Rank  Pl1_Rank  \\\n",
       "0  2000-01-03    Ljubicic I.      Dosedel S.  1.0        77        63   \n",
       "1  2000-01-03     Enqvist T.      Clement A.  0.0         5        56   \n",
       "2  2000-01-03  Baccanello P.       Escude N.  1.0       655        40   \n",
       "3  2000-01-03     Federer R.  Knippschild J.  0.0        65        87   \n",
       "4  2000-01-03  Woodbridge T.     Fromberg R.  1.0       198        81   \n",
       "\n",
       "   Avg_Pl0  Avg_Pl1  Max_Pl1  Max_Pl0  ...  Pl1 Recent Form  Pl1 Form  \\\n",
       "0      NaN      NaN      NaN      NaN  ...              0.0       0.0   \n",
       "1      NaN      NaN      NaN      NaN  ...              0.0       0.0   \n",
       "2      NaN      NaN      NaN      NaN  ...              0.0       0.0   \n",
       "3      NaN      NaN      NaN      NaN  ...              0.0       0.0   \n",
       "4      NaN      NaN      NaN      NaN  ...              0.0       0.0   \n",
       "\n",
       "   Pl0 Perf. vs Similar Opponent  Pl1 Perf. vs Similar Opponent  \\\n",
       "0                           0.66                           0.17   \n",
       "1                           0.58                           0.24   \n",
       "2                           0.00                           0.91   \n",
       "3                           0.90                           0.30   \n",
       "4                           0.29                           0.36   \n",
       "\n",
       "   Pl0 Surface Performance  Pl1 Surface Performance  H2H Index  Exp Index  \\\n",
       "0                     0.61                     0.40        0.0        0.0   \n",
       "1                     0.56                     0.51        0.0        0.0   \n",
       "2                     0.14                     0.65        0.0        0.0   \n",
       "3                     0.84                     0.10        0.0        0.0   \n",
       "4                     0.27                     0.46        0.0        0.0   \n",
       "\n",
       "   Reliability Pl0  Reliability Pl1  \n",
       "0         0.687008         0.000000  \n",
       "1         0.625000         0.640805  \n",
       "2         0.750000         0.680851  \n",
       "3         0.868249         1.000000  \n",
       "4         0.000000         0.000000  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before picking up our models, we have to extract the inputs and the targets from this dataset.\n",
    "The target variable is only one, the \"Won\" column.\n",
    "The inputs variables start with the dummy categories we introduced in the preprocessing stage until the last columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date',\n",
       " 'Player 0',\n",
       " 'Player 1',\n",
       " 'Won',\n",
       " 'Pl0_Rank',\n",
       " 'Pl1_Rank',\n",
       " 'Avg_Pl0',\n",
       " 'Avg_Pl1',\n",
       " 'Max_Pl1',\n",
       " 'Max_Pl0',\n",
       " 'PS_Pl0',\n",
       " 'PS_Pl1',\n",
       " 'B365_Pl0',\n",
       " 'B365_Pl1',\n",
       " 'Indoor',\n",
       " 'Outdoor',\n",
       " 'Carpet',\n",
       " 'Clay',\n",
       " 'Grass',\n",
       " 'Hard',\n",
       " 'ATP250',\n",
       " 'ATP500',\n",
       " 'Grand Slam',\n",
       " 'Masters 1000',\n",
       " 'Masters Cup',\n",
       " '1st Round',\n",
       " '2nd Round',\n",
       " '3rd Round',\n",
       " '4th Round',\n",
       " 'Quarterfinals',\n",
       " 'Round Robin',\n",
       " 'Semifinals',\n",
       " 'The Final',\n",
       " 'Rank Index',\n",
       " 'Pl0 Recent Form',\n",
       " 'Pl0 Form',\n",
       " 'Pl1 Recent Form',\n",
       " 'Pl1 Form',\n",
       " 'Pl0 Perf. vs Similar Opponent',\n",
       " 'Pl1 Perf. vs Similar Opponent',\n",
       " 'Pl0 Surface Performance',\n",
       " 'Pl1 Surface Performance',\n",
       " 'H2H Index',\n",
       " 'Exp Index',\n",
       " 'Reliability Pl0',\n",
       " 'Reliability Pl1']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before splitting our dataset in inputs and targets, we specify a subset of the dataframe containing only matches that are not going to be used in the \"Betting simulation\" stage, so for modeling we're going to pick only matches that don't have information about average and max odds for the players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Player 0</th>\n",
       "      <th>Player 1</th>\n",
       "      <th>Won</th>\n",
       "      <th>Pl0_Rank</th>\n",
       "      <th>Pl1_Rank</th>\n",
       "      <th>Avg_Pl0</th>\n",
       "      <th>Avg_Pl1</th>\n",
       "      <th>Max_Pl1</th>\n",
       "      <th>Max_Pl0</th>\n",
       "      <th>...</th>\n",
       "      <th>Pl1 Recent Form</th>\n",
       "      <th>Pl1 Form</th>\n",
       "      <th>Pl0 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl1 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl0 Surface Performance</th>\n",
       "      <th>Pl1 Surface Performance</th>\n",
       "      <th>H2H Index</th>\n",
       "      <th>Exp Index</th>\n",
       "      <th>Reliability Pl0</th>\n",
       "      <th>Reliability Pl1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>Ljubicic I.</td>\n",
       "      <td>Dosedel S.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.687008</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>Enqvist T.</td>\n",
       "      <td>Clement A.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.640805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>Baccanello P.</td>\n",
       "      <td>Escude N.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>655</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.680851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>Federer R.</td>\n",
       "      <td>Knippschild J.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.868249</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>Woodbridge T.</td>\n",
       "      <td>Fromberg R.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>198</td>\n",
       "      <td>81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Player 0        Player 1  Won  Pl0_Rank  Pl1_Rank  \\\n",
       "0  2000-01-03    Ljubicic I.      Dosedel S.  1.0        77        63   \n",
       "1  2000-01-03     Enqvist T.      Clement A.  0.0         5        56   \n",
       "2  2000-01-03  Baccanello P.       Escude N.  1.0       655        40   \n",
       "3  2000-01-03     Federer R.  Knippschild J.  0.0        65        87   \n",
       "4  2000-01-03  Woodbridge T.     Fromberg R.  1.0       198        81   \n",
       "\n",
       "   Avg_Pl0  Avg_Pl1  Max_Pl1  Max_Pl0  ...  Pl1 Recent Form  Pl1 Form  \\\n",
       "0      NaN      NaN      NaN      NaN  ...              0.0       0.0   \n",
       "1      NaN      NaN      NaN      NaN  ...              0.0       0.0   \n",
       "2      NaN      NaN      NaN      NaN  ...              0.0       0.0   \n",
       "3      NaN      NaN      NaN      NaN  ...              0.0       0.0   \n",
       "4      NaN      NaN      NaN      NaN  ...              0.0       0.0   \n",
       "\n",
       "   Pl0 Perf. vs Similar Opponent  Pl1 Perf. vs Similar Opponent  \\\n",
       "0                           0.66                           0.17   \n",
       "1                           0.58                           0.24   \n",
       "2                           0.00                           0.91   \n",
       "3                           0.90                           0.30   \n",
       "4                           0.29                           0.36   \n",
       "\n",
       "   Pl0 Surface Performance  Pl1 Surface Performance  H2H Index  Exp Index  \\\n",
       "0                     0.61                     0.40        0.0        0.0   \n",
       "1                     0.56                     0.51        0.0        0.0   \n",
       "2                     0.14                     0.65        0.0        0.0   \n",
       "3                     0.84                     0.10        0.0        0.0   \n",
       "4                     0.27                     0.46        0.0        0.0   \n",
       "\n",
       "   Reliability Pl0  Reliability Pl1  \n",
       "0         0.687008         0.000000  \n",
       "1         0.625000         0.640805  \n",
       "2         0.750000         0.680851  \n",
       "3         0.868249         1.000000  \n",
       "4         0.000000         0.000000  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nobets_df = df[(df[\"Avg_Pl0\"].isnull()) | (df[\"Avg_Pl1\"].isnull()) | (df[\"Max_Pl0\"].isnull()) | (df[\"Max_Pl1\"].isnull())]\n",
    "nobets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = nobets_df.iloc[:, 14:]\n",
    "targets = nobets_df.iloc[:, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at \"inputs\" and \"targets\" content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Indoor</th>\n",
       "      <th>Outdoor</th>\n",
       "      <th>Carpet</th>\n",
       "      <th>Clay</th>\n",
       "      <th>Grass</th>\n",
       "      <th>Hard</th>\n",
       "      <th>ATP250</th>\n",
       "      <th>ATP500</th>\n",
       "      <th>Grand Slam</th>\n",
       "      <th>Masters 1000</th>\n",
       "      <th>...</th>\n",
       "      <th>Pl1 Recent Form</th>\n",
       "      <th>Pl1 Form</th>\n",
       "      <th>Pl0 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl1 Perf. vs Similar Opponent</th>\n",
       "      <th>Pl0 Surface Performance</th>\n",
       "      <th>Pl1 Surface Performance</th>\n",
       "      <th>H2H Index</th>\n",
       "      <th>Exp Index</th>\n",
       "      <th>Reliability Pl0</th>\n",
       "      <th>Reliability Pl1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.687008</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.640805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.680851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.868249</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Indoor  Outdoor  Carpet  Clay  Grass  Hard  ATP250  ATP500  Grand Slam  \\\n",
       "0       0        1       0     0      0     1       1       0           0   \n",
       "1       0        1       0     0      0     1       1       0           0   \n",
       "2       0        1       0     0      0     1       1       0           0   \n",
       "3       0        1       0     0      0     1       1       0           0   \n",
       "4       0        1       0     0      0     1       1       0           0   \n",
       "\n",
       "   Masters 1000  ...  Pl1 Recent Form  Pl1 Form  \\\n",
       "0             0  ...              0.0       0.0   \n",
       "1             0  ...              0.0       0.0   \n",
       "2             0  ...              0.0       0.0   \n",
       "3             0  ...              0.0       0.0   \n",
       "4             0  ...              0.0       0.0   \n",
       "\n",
       "   Pl0 Perf. vs Similar Opponent  Pl1 Perf. vs Similar Opponent  \\\n",
       "0                           0.66                           0.17   \n",
       "1                           0.58                           0.24   \n",
       "2                           0.00                           0.91   \n",
       "3                           0.90                           0.30   \n",
       "4                           0.29                           0.36   \n",
       "\n",
       "   Pl0 Surface Performance  Pl1 Surface Performance  H2H Index  Exp Index  \\\n",
       "0                     0.61                     0.40        0.0        0.0   \n",
       "1                     0.56                     0.51        0.0        0.0   \n",
       "2                     0.14                     0.65        0.0        0.0   \n",
       "3                     0.84                     0.10        0.0        0.0   \n",
       "4                     0.27                     0.46        0.0        0.0   \n",
       "\n",
       "   Reliability Pl0  Reliability Pl1  \n",
       "0         0.687008         0.000000  \n",
       "1         0.625000         0.640805  \n",
       "2         0.750000         0.680851  \n",
       "3         0.868249         1.000000  \n",
       "4         0.000000         0.000000  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    0.0\n",
       "2    1.0\n",
       "3    0.0\n",
       "4    1.0\n",
       "Name: Won, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to split the data into training and testing data.\n",
    "We'll use a 75:25 split, and since we assume each match is independent from the others, we won't shuffle the data randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(inputs, targets, test_size=0.25, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Let's start off with the logistic regression, and see how accurately predicts winners and losers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lreg = LogisticRegression(max_iter=10000, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=2,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lreg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7195831641629449\n"
     ]
    }
   ],
   "source": [
    "score = lreg.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression predicts correctly more than 7 matches out of 10!\n",
    "\n",
    "Since we structured our data to have as many '0' targets than '1' targets, a random model would have approximately 50% accuracy.\n",
    "Jumping from 50% to almost 72% is definetely a good result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "Another popular classifier model is the SVM, Support Vector Machine.\n",
    "Let's see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(kernel = 'rbf')\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7185004736770876\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM model has a 0.718 accuracy, just below the Logistic Regression model!\n",
    "Let's see if we can find better models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier\n",
    "\n",
    "Let's try out the Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6302611990797131\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Decision Tree model, as we can see, is not a very good choice. It returns only a 0.63 prediction accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors\n",
    "\n",
    "Let's see if the KNN model can do a better job than the Logistic Regression and the SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the KNN model we have to pick the right K value, so we're going to fit our model with several values from 1 to 8, and we'll compare the errors of each run.\n",
    "Finally, we'll run the model with the appropriate K value and check its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = []\n",
    "\n",
    "# Calculating error for K values between 1 and 8\n",
    "for i in range(1, 9):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(x_train, y_train)\n",
    "    pred_i = knn.predict(x_test)\n",
    "    error.append(np.mean(pred_i != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Mean Error')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, 9), error, color='red', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='blue', markersize=10)\n",
    "plt.title('Error Rate K Value')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('Mean Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the plot above, we obtain the lowest error with K = 7, so let's use 7 as K parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=7)\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.67      0.67      3688\n",
      "         1.0       0.67      0.66      0.67      3701\n",
      "\n",
      "    accuracy                           0.67      7389\n",
      "   macro avg       0.67      0.67      0.67      7389\n",
      "weighted avg       0.67      0.67      0.67      7389\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN accuracy is around 0.67, so not that great.\n",
    "Let's try Neural Networks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Networks\n",
    "\n",
    "Finally, let's see if we can build a neural network that can achieve a greater accuracy than the Logistic Regression and SVM models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to achieve not only a classification prediction but a probability also, for any given match, the last layer of the neural network will have softmax activation function.\n",
    "However, to use it, we have to build a special \"output\" layer with size 2 and not 1.\n",
    "So let's transform the \"targets\" variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_for_nn = pd.DataFrame()\n",
    "for items in targets.iteritems():\n",
    "    ix = items[0]\n",
    "    winner = items[1]\n",
    "    if winner == 0:\n",
    "        targets_for_nn.at[ix, 'Player 0'] = 1\n",
    "        targets_for_nn.at[ix, 'Player 1'] = 0\n",
    "    else:\n",
    "        targets_for_nn.at[ix, 'Player 0'] = 0\n",
    "        targets_for_nn.at[ix, 'Player 1'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's split again, with targets_for_nn as target\n",
    "x_train, x_test, y_train, y_test = train_test_split(inputs, targets_for_nn, test_size=0.25, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = inputs.shape[1]\n",
    "\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(1000, input_dim=input_cols, activation='relu'))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(60, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dense(7, activation='relu'))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "22165/22165 [==============================] - 4s 187us/step - loss: 0.5937 - accuracy: 0.6780\n",
      "Epoch 2/10\n",
      "22165/22165 [==============================] - 4s 174us/step - loss: 0.5593 - accuracy: 0.69770s - los\n",
      "Epoch 3/10\n",
      "22165/22165 [==============================] - 4s 173us/step - loss: 0.5529 - accuracy: 0.7034\n",
      "Epoch 4/10\n",
      "22165/22165 [==============================] - 4s 175us/step - loss: 0.5486 - accuracy: 0.7039\n",
      "Epoch 5/10\n",
      "22165/22165 [==============================] - 4s 180us/step - loss: 0.5466 - accuracy: 0.7044\n",
      "Epoch 6/10\n",
      "22165/22165 [==============================] - 4s 175us/step - loss: 0.5453 - accuracy: 0.7078\n",
      "Epoch 7/10\n",
      "22165/22165 [==============================] - 4s 171us/step - loss: 0.5458 - accuracy: 0.7067\n",
      "Epoch 8/10\n",
      "22165/22165 [==============================] - 5s 204us/step - loss: 0.5414 - accuracy: 0.7099\n",
      "Epoch 9/10\n",
      "22165/22165 [==============================] - 5s 214us/step - loss: 0.5386 - accuracy: 0.7096\n",
      "Epoch 10/10\n",
      "22165/22165 [==============================] - 5s 214us/step - loss: 0.5386 - accuracy: 0.7097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21500f89a48>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7389/7389 [==============================] - 1s 133us/step\n",
      "Test accuracy: 0.7175531387329102\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we achieved 0.717 accuracy, very similar to the Logistic Regression and SVM models.\n",
    "\n",
    "However, we'll decide to make use of the Logistic Regression model since we can predicts probabilities that each player has to win the match!\n",
    "\n",
    "In this way, we can define the \"predicted\" odds for any given match calculating the logistic regression formula on the inputs features.\n",
    "\n",
    "So let's save our Logistic Regression model, we're going to use it in the next notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'logistic_regression.lr'\n",
    "pickle.dump(lreg, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have saved our model, let's create a coefficients dataframe, so that we associate each input column with the appropriate weight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(inputs.columns)\n",
    "coefs = lreg.coef_.tolist()[0]\n",
    "\n",
    "coef_df_list = []\n",
    "for i in range(0,inputs.shape[1]):\n",
    "    col = cols[i]\n",
    "    coef = coefs[i]\n",
    "    coef_df_list.append({\"Column\":col,\"Coef\":coef})\n",
    "\n",
    "coef_df = pd.DataFrame(coef_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df.to_csv(\"csv/Coefficients.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
